{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>데이터 분석 프로젝트</h1><br></center>\n",
    "<center><h3>병원 개폐업 예측 프로젝트</h3><br></center>\n",
    "\n",
    "<div style=\"text-align:right\">다 파악했조<br></div>\n",
    "<div style=\"text-align:right\"> 조원 강청우, 김수정, 이정승, 정지연, 정호영</div>\n",
    "\n",
    "<h3>1. 데이터 선정</h3><br>\n",
    "DACON – 데이터 분석 대회를 주최하고 서로 평가하는 대회 및 커뮤니티 사이트<br>\n",
    "DACON에서 제공하는 병원 개/폐업 분류 예측 경진대회 데이터 사용<br>\n",
    "기존 병원의 경영 여부를 통해 폐업하는 병원을 예측하는 모델 생성<br>\n",
    "\n",
    "<h3>2. 데이터 설명</h3><br>\n",
    "한국의 약 430개 병원의 재무제표 자료, 직원 수, 지역 정보 제공<br>\n",
    "예측 결과물은 정확도로 평가<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. 필요 모듈 및 라이브러리 불러오기</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경고메세지 끄기\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 넘파이 판다스 모듈\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 사이킷런 데이터 전처리 모듈\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "# 사이킷런 모델 클래스\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 사이킷런 모델 평가 지표\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# 판다스 시각화 분석 툴\n",
    "from pandas_visual_analysis import VisualAnalysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. 데이터 분석</h3><br>\n",
    "가. 데이터 탐색<br>\n",
    "나. 결측치 확인 및 처리<br>\n",
    "다. 탐색적 데이터 분석 및 Feature Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가. 데이터 탐색<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>OC</th>\n",
       "      <th>sido</th>\n",
       "      <th>sgg</th>\n",
       "      <th>openDate</th>\n",
       "      <th>bedCount</th>\n",
       "      <th>instkind</th>\n",
       "      <th>revenue1</th>\n",
       "      <th>salescost1</th>\n",
       "      <th>sga1</th>\n",
       "      <th>...</th>\n",
       "      <th>debt2</th>\n",
       "      <th>liquidLiabilities2</th>\n",
       "      <th>shortLoan2</th>\n",
       "      <th>NCLiabilities2</th>\n",
       "      <th>longLoan2</th>\n",
       "      <th>netAsset2</th>\n",
       "      <th>surplus2</th>\n",
       "      <th>employee1</th>\n",
       "      <th>employee2</th>\n",
       "      <th>ownerChange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>open</td>\n",
       "      <td>choongnam</td>\n",
       "      <td>73</td>\n",
       "      <td>20071228</td>\n",
       "      <td>175.0</td>\n",
       "      <td>nursing_hospital</td>\n",
       "      <td>4.217530e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.961135e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>7.589937e+08</td>\n",
       "      <td>2.228769e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.361169e+08</td>\n",
       "      <td>3.900000e+08</td>\n",
       "      <td>2.619290e+09</td>\n",
       "      <td>1.271224e+09</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>open</td>\n",
       "      <td>gyeongnam</td>\n",
       "      <td>32</td>\n",
       "      <td>19970401</td>\n",
       "      <td>410.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>801.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>open</td>\n",
       "      <td>gyeonggi</td>\n",
       "      <td>89</td>\n",
       "      <td>20161228</td>\n",
       "      <td>468.0</td>\n",
       "      <td>nursing_hospital</td>\n",
       "      <td>1.004522e+09</td>\n",
       "      <td>5.154837e+08</td>\n",
       "      <td>4.472197e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>234.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>open</td>\n",
       "      <td>incheon</td>\n",
       "      <td>141</td>\n",
       "      <td>20000814</td>\n",
       "      <td>353.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>7.250734e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.067740e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>3.775501e+10</td>\n",
       "      <td>1.701860e+10</td>\n",
       "      <td>9.219427e+09</td>\n",
       "      <td>2.073641e+10</td>\n",
       "      <td>1.510000e+10</td>\n",
       "      <td>1.295427e+10</td>\n",
       "      <td>7.740829e+09</td>\n",
       "      <td>663.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>open</td>\n",
       "      <td>gyeongnam</td>\n",
       "      <td>32</td>\n",
       "      <td>20050901</td>\n",
       "      <td>196.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>4.904354e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.765605e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.143259e+10</td>\n",
       "      <td>3.007259e+10</td>\n",
       "      <td>1.759375e+10</td>\n",
       "      <td>2.136001e+10</td>\n",
       "      <td>1.410803e+10</td>\n",
       "      <td>5.561941e+06</td>\n",
       "      <td>9.025550e+09</td>\n",
       "      <td>206.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>422</td>\n",
       "      <td>open</td>\n",
       "      <td>jeonnam</td>\n",
       "      <td>178</td>\n",
       "      <td>20050211</td>\n",
       "      <td>214.0</td>\n",
       "      <td>nursing_hospital</td>\n",
       "      <td>7.614697e+09</td>\n",
       "      <td>4.153475e+08</td>\n",
       "      <td>5.903119e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>9.423771e+09</td>\n",
       "      <td>2.618201e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.805570e+09</td>\n",
       "      <td>5.930000e+09</td>\n",
       "      <td>5.379502e+09</td>\n",
       "      <td>8.116416e+08</td>\n",
       "      <td>193.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>423</td>\n",
       "      <td>close</td>\n",
       "      <td>choongnam</td>\n",
       "      <td>159</td>\n",
       "      <td>20140618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hospital</td>\n",
       "      <td>6.717144e+09</td>\n",
       "      <td>8.200000e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>426</td>\n",
       "      <td>close</td>\n",
       "      <td>gyeongbuk</td>\n",
       "      <td>107</td>\n",
       "      <td>19830705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hospital</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.479428e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>6.370097e+09</td>\n",
       "      <td>2.170973e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.199124e+09</td>\n",
       "      <td>2.498749e+09</td>\n",
       "      <td>3.259161e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>427</td>\n",
       "      <td>close</td>\n",
       "      <td>gyeonggi</td>\n",
       "      <td>169</td>\n",
       "      <td>20070101</td>\n",
       "      <td>180.0</td>\n",
       "      <td>nursing_hospital</td>\n",
       "      <td>2.116892e+09</td>\n",
       "      <td>2.681748e+08</td>\n",
       "      <td>3.286245e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>6.392336e+08</td>\n",
       "      <td>6.400000e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>428</td>\n",
       "      <td>open</td>\n",
       "      <td>seoul</td>\n",
       "      <td>79</td>\n",
       "      <td>20011017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>traditional_hospital</td>\n",
       "      <td>1.340971e+09</td>\n",
       "      <td>8.108450e+08</td>\n",
       "      <td>5.043409e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>5.349000e+09</td>\n",
       "      <td>3.123072e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.225928e+09</td>\n",
       "      <td>2.190000e+09</td>\n",
       "      <td>5.536178e+09</td>\n",
       "      <td>6.269440e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     inst_id      OC       sido  sgg  openDate  bedCount  \\\n",
       "0          1    open  choongnam   73  20071228     175.0   \n",
       "1          3    open  gyeongnam   32  19970401     410.0   \n",
       "2          4    open   gyeonggi   89  20161228     468.0   \n",
       "3          7    open    incheon  141  20000814     353.0   \n",
       "4          9    open  gyeongnam   32  20050901     196.0   \n",
       "..       ...     ...        ...  ...       ...       ...   \n",
       "296      422    open    jeonnam  178  20050211     214.0   \n",
       "297      423   close  choongnam  159  20140618       NaN   \n",
       "298      426   close  gyeongbuk  107  19830705       NaN   \n",
       "299      427   close   gyeonggi  169  20070101     180.0   \n",
       "300      428    open      seoul   79  20011017       NaN   \n",
       "\n",
       "                 instkind      revenue1    salescost1          sga1  ...  \\\n",
       "0        nursing_hospital  4.217530e+09  0.000000e+00  3.961135e+09  ...   \n",
       "1        general_hospital           NaN           NaN           NaN  ...   \n",
       "2        nursing_hospital  1.004522e+09  5.154837e+08  4.472197e+08  ...   \n",
       "3        general_hospital  7.250734e+10  0.000000e+00  7.067740e+10  ...   \n",
       "4        general_hospital  4.904354e+10  0.000000e+00  4.765605e+10  ...   \n",
       "..                    ...           ...           ...           ...  ...   \n",
       "296      nursing_hospital  7.614697e+09  4.153475e+08  5.903119e+09  ...   \n",
       "297              hospital  6.717144e+09  8.200000e+09  0.000000e+00  ...   \n",
       "298              hospital  0.000000e+00  0.000000e+00  5.479428e+07  ...   \n",
       "299      nursing_hospital  2.116892e+09  2.681748e+08  3.286245e+09  ...   \n",
       "300  traditional_hospital  1.340971e+09  8.108450e+08  5.043409e+08  ...   \n",
       "\n",
       "            debt2  liquidLiabilities2    shortLoan2  NCLiabilities2  \\\n",
       "0    7.589937e+08        2.228769e+08  0.000000e+00    5.361169e+08   \n",
       "1             NaN                 NaN           NaN             NaN   \n",
       "2    0.000000e+00        0.000000e+00  0.000000e+00    0.000000e+00   \n",
       "3    3.775501e+10        1.701860e+10  9.219427e+09    2.073641e+10   \n",
       "4    5.143259e+10        3.007259e+10  1.759375e+10    2.136001e+10   \n",
       "..            ...                 ...           ...             ...   \n",
       "296  9.423771e+09        2.618201e+09  0.000000e+00    6.805570e+09   \n",
       "297  0.000000e+00        0.000000e+00  0.000000e+00    0.000000e+00   \n",
       "298  6.370097e+09        2.170973e+09  0.000000e+00    4.199124e+09   \n",
       "299  6.392336e+08        6.400000e+09  0.000000e+00    0.000000e+00   \n",
       "300  5.349000e+09        3.123072e+09  0.000000e+00    2.225928e+09   \n",
       "\n",
       "        longLoan2     netAsset2      surplus2  employee1  employee2  \\\n",
       "0    3.900000e+08  2.619290e+09  1.271224e+09       62.0       64.0   \n",
       "1             NaN           NaN           NaN      801.0      813.0   \n",
       "2    0.000000e+00  0.000000e+00  0.000000e+00      234.0        1.0   \n",
       "3    1.510000e+10  1.295427e+10  7.740829e+09      663.0      663.0   \n",
       "4    1.410803e+10  5.561941e+06  9.025550e+09      206.0      197.0   \n",
       "..            ...           ...           ...        ...        ...   \n",
       "296  5.930000e+09  5.379502e+09  8.116416e+08      193.0      141.0   \n",
       "297  0.000000e+00  0.000000e+00  0.000000e+00       79.0       79.0   \n",
       "298  2.498749e+09  3.259161e+09  0.000000e+00        NaN        NaN   \n",
       "299  0.000000e+00  0.000000e+00  0.000000e+00      100.0        NaN   \n",
       "300  2.190000e+09  5.536178e+09  6.269440e+09       15.0       15.0   \n",
       "\n",
       "     ownerChange  \n",
       "0           same  \n",
       "1           same  \n",
       "2           same  \n",
       "3           same  \n",
       "4           same  \n",
       "..           ...  \n",
       "296         same  \n",
       "297         same  \n",
       "298          NaN  \n",
       "299          NaN  \n",
       "300         same  \n",
       "\n",
       "[301 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#csv 파일 로드 및 데이터 프레임 미리보기\n",
    "data = pd.read_csv('data/train.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data columns :\n",
      "['inst_id', 'OC', 'sido', 'sgg', 'openDate', 'bedCount', 'instkind', 'revenue1', 'salescost1', 'sga1', 'salary1', 'noi1', 'noe1', 'interest1', 'ctax1', 'profit1', 'liquidAsset1', 'quickAsset1', 'receivableS1', 'inventoryAsset1', 'nonCAsset1', 'tanAsset1', 'OnonCAsset1', 'receivableL1', 'debt1', 'liquidLiabilities1', 'shortLoan1', 'NCLiabilities1', 'longLoan1', 'netAsset1', 'surplus1', 'revenue2', 'salescost2', 'sga2', 'salary2', 'noi2', 'noe2', 'interest2', 'ctax2', 'profit2', 'liquidAsset2', 'quickAsset2', 'receivableS2', 'inventoryAsset2', 'nonCAsset2', 'tanAsset2', 'OnonCAsset2', 'receivableL2', 'debt2', 'liquidLiabilities2', 'shortLoan2', 'NCLiabilities2', 'longLoan2', 'netAsset2', 'surplus2', 'employee1', 'employee2', 'ownerChange']\n",
      "----------------------------------------------------------------------------\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "print('data columns :')\n",
    "print(data.columns.to_list())\n",
    "print('----------------------------------------------------------------------------')\n",
    "print(len(data.columns.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inst_id                 int64\n",
       "OC                     object\n",
       "sido                   object\n",
       "sgg                     int64\n",
       "openDate                int64\n",
       "bedCount              float64\n",
       "instkind               object\n",
       "revenue1              float64\n",
       "salescost1            float64\n",
       "sga1                  float64\n",
       "salary1               float64\n",
       "noi1                  float64\n",
       "noe1                  float64\n",
       "interest1             float64\n",
       "ctax1                 float64\n",
       "profit1               float64\n",
       "liquidAsset1          float64\n",
       "quickAsset1           float64\n",
       "receivableS1          float64\n",
       "inventoryAsset1       float64\n",
       "nonCAsset1            float64\n",
       "tanAsset1             float64\n",
       "OnonCAsset1           float64\n",
       "receivableL1          float64\n",
       "debt1                 float64\n",
       "liquidLiabilities1    float64\n",
       "shortLoan1            float64\n",
       "NCLiabilities1        float64\n",
       "longLoan1             float64\n",
       "netAsset1             float64\n",
       "surplus1              float64\n",
       "revenue2              float64\n",
       "salescost2            float64\n",
       "sga2                  float64\n",
       "salary2               float64\n",
       "noi2                  float64\n",
       "noe2                  float64\n",
       "interest2             float64\n",
       "ctax2                 float64\n",
       "profit2               float64\n",
       "liquidAsset2          float64\n",
       "quickAsset2           float64\n",
       "receivableS2          float64\n",
       "inventoryAsset2       float64\n",
       "nonCAsset2            float64\n",
       "tanAsset2             float64\n",
       "OnonCAsset2           float64\n",
       "receivableL2          float64\n",
       "debt2                 float64\n",
       "liquidLiabilities2    float64\n",
       "shortLoan2            float64\n",
       "NCLiabilities2        float64\n",
       "longLoan2             float64\n",
       "netAsset2             float64\n",
       "surplus2              float64\n",
       "employee1             float64\n",
       "employee2             float64\n",
       "ownerChange            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 타입 확인하기\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_num_cat(data) -> data\n",
    "## data : DataFrame\n",
    "# output\n",
    "## data : DataFrame, 모든 칼럼의 Null값을 대체하여 채워 넣은 DataFrame\n",
    "def split_num_cat(data):\n",
    "    categoric_data = []\n",
    "    numeric_data = []\n",
    "    \n",
    "    # 카테고리 변수와 수치형 변수 분리\n",
    "    for col, dtype in zip(data.columns.to_list(),data.dtypes.to_list()):\n",
    "        if dtype == 'float64':\n",
    "            numeric_data.append(col)\n",
    "        else:\n",
    "            categoric_data.append(col)\n",
    "    \n",
    "    categoric_data = list(set(categoric_data))\n",
    "    numeric_data = list(set(numeric_data))\n",
    "    if 'inst_id' in categoric_data:\n",
    "        categoric_data.remove('inst_id')\n",
    "    if 'ownerChange' in categoric_data:\n",
    "        categoric_data.remove('ownerChange')\n",
    "    return numeric_data, categoric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data, categoric_data = split_num_cat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>sgg</th>\n",
       "      <th>openDate</th>\n",
       "      <th>bedCount</th>\n",
       "      <th>revenue1</th>\n",
       "      <th>salescost1</th>\n",
       "      <th>sga1</th>\n",
       "      <th>salary1</th>\n",
       "      <th>noi1</th>\n",
       "      <th>noe1</th>\n",
       "      <th>...</th>\n",
       "      <th>receivableL2</th>\n",
       "      <th>debt2</th>\n",
       "      <th>liquidLiabilities2</th>\n",
       "      <th>shortLoan2</th>\n",
       "      <th>NCLiabilities2</th>\n",
       "      <th>longLoan2</th>\n",
       "      <th>netAsset2</th>\n",
       "      <th>surplus2</th>\n",
       "      <th>employee1</th>\n",
       "      <th>employee2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>301.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>3.010000e+02</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>2.930000e+02</td>\n",
       "      <td>2.930000e+02</td>\n",
       "      <td>2.930000e+02</td>\n",
       "      <td>2.930000e+02</td>\n",
       "      <td>2.930000e+02</td>\n",
       "      <td>2.930000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>2.930000e+02</td>\n",
       "      <td>2.930000e+02</td>\n",
       "      <td>2.930000e+02</td>\n",
       "      <td>2.930000e+02</td>\n",
       "      <td>2.930000e+02</td>\n",
       "      <td>2.930000e+02</td>\n",
       "      <td>2.930000e+02</td>\n",
       "      <td>2.930000e+02</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>288.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>219.056478</td>\n",
       "      <td>81.039867</td>\n",
       "      <td>2.005013e+07</td>\n",
       "      <td>145.709459</td>\n",
       "      <td>1.288175e+10</td>\n",
       "      <td>2.014903e+09</td>\n",
       "      <td>1.033244e+10</td>\n",
       "      <td>5.654115e+09</td>\n",
       "      <td>2.696151e+08</td>\n",
       "      <td>5.115870e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>2.226700e+05</td>\n",
       "      <td>8.146026e+09</td>\n",
       "      <td>3.860584e+09</td>\n",
       "      <td>1.510050e+09</td>\n",
       "      <td>4.471247e+09</td>\n",
       "      <td>2.709979e+09</td>\n",
       "      <td>5.273919e+09</td>\n",
       "      <td>9.786279e+08</td>\n",
       "      <td>142.546392</td>\n",
       "      <td>134.326389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>121.234869</td>\n",
       "      <td>50.969714</td>\n",
       "      <td>8.893815e+04</td>\n",
       "      <td>118.923890</td>\n",
       "      <td>2.043543e+10</td>\n",
       "      <td>7.460271e+09</td>\n",
       "      <td>1.493886e+10</td>\n",
       "      <td>8.083343e+09</td>\n",
       "      <td>8.023701e+08</td>\n",
       "      <td>1.060379e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>3.811496e+06</td>\n",
       "      <td>1.255800e+10</td>\n",
       "      <td>6.797242e+09</td>\n",
       "      <td>2.953412e+09</td>\n",
       "      <td>7.659580e+09</td>\n",
       "      <td>4.564001e+09</td>\n",
       "      <td>1.081259e+10</td>\n",
       "      <td>4.688798e+09</td>\n",
       "      <td>160.191073</td>\n",
       "      <td>151.061786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.978012e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.014780e+10</td>\n",
       "      <td>-2.781507e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>112.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>2.001102e+07</td>\n",
       "      <td>52.750000</td>\n",
       "      <td>3.252112e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.758201e+09</td>\n",
       "      <td>1.626053e+09</td>\n",
       "      <td>8.217133e+06</td>\n",
       "      <td>8.013395e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.283220e+09</td>\n",
       "      <td>2.855741e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.557878e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.017573e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>53.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>230.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2.007113e+07</td>\n",
       "      <td>136.500000</td>\n",
       "      <td>5.524218e+09</td>\n",
       "      <td>2.104105e+08</td>\n",
       "      <td>4.684074e+09</td>\n",
       "      <td>2.659892e+09</td>\n",
       "      <td>4.363764e+07</td>\n",
       "      <td>1.831965e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.784553e+09</td>\n",
       "      <td>1.454050e+09</td>\n",
       "      <td>8.542549e+07</td>\n",
       "      <td>1.969747e+09</td>\n",
       "      <td>1.100000e+09</td>\n",
       "      <td>2.894970e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>321.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>2.011102e+07</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>1.274839e+10</td>\n",
       "      <td>9.105278e+08</td>\n",
       "      <td>1.077876e+10</td>\n",
       "      <td>6.363400e+09</td>\n",
       "      <td>2.050331e+08</td>\n",
       "      <td>4.203330e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.465053e+09</td>\n",
       "      <td>4.364714e+09</td>\n",
       "      <td>1.567967e+09</td>\n",
       "      <td>4.905441e+09</td>\n",
       "      <td>3.360000e+09</td>\n",
       "      <td>5.370285e+09</td>\n",
       "      <td>1.014447e+08</td>\n",
       "      <td>181.500000</td>\n",
       "      <td>170.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>428.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>2.017061e+07</td>\n",
       "      <td>656.000000</td>\n",
       "      <td>1.510000e+11</td>\n",
       "      <td>9.850332e+10</td>\n",
       "      <td>1.030000e+11</td>\n",
       "      <td>6.403559e+10</td>\n",
       "      <td>9.144171e+09</td>\n",
       "      <td>8.686380e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>6.524231e+07</td>\n",
       "      <td>8.508858e+10</td>\n",
       "      <td>6.846878e+10</td>\n",
       "      <td>1.759375e+10</td>\n",
       "      <td>5.150388e+10</td>\n",
       "      <td>3.256147e+10</td>\n",
       "      <td>1.250000e+11</td>\n",
       "      <td>6.852730e+10</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          inst_id         sgg      openDate    bedCount      revenue1  \\\n",
       "count  301.000000  301.000000  3.010000e+02  296.000000  2.930000e+02   \n",
       "mean   219.056478   81.039867  2.005013e+07  145.709459  1.288175e+10   \n",
       "std    121.234869   50.969714  8.893815e+04  118.923890  2.043543e+10   \n",
       "min      1.000000    1.000000  1.978012e+07    0.000000  0.000000e+00   \n",
       "25%    112.000000   37.000000  2.001102e+07   52.750000  3.252112e+09   \n",
       "50%    230.000000   75.000000  2.007113e+07  136.500000  5.524218e+09   \n",
       "75%    321.000000  123.000000  2.011102e+07  193.000000  1.274839e+10   \n",
       "max    428.000000  178.000000  2.017061e+07  656.000000  1.510000e+11   \n",
       "\n",
       "         salescost1          sga1       salary1          noi1          noe1  \\\n",
       "count  2.930000e+02  2.930000e+02  2.930000e+02  2.930000e+02  2.930000e+02   \n",
       "mean   2.014903e+09  1.033244e+10  5.654115e+09  2.696151e+08  5.115870e+08   \n",
       "std    7.460271e+09  1.493886e+10  8.083343e+09  8.023701e+08  1.060379e+09   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  2.758201e+09  1.626053e+09  8.217133e+06  8.013395e+07   \n",
       "50%    2.104105e+08  4.684074e+09  2.659892e+09  4.363764e+07  1.831965e+08   \n",
       "75%    9.105278e+08  1.077876e+10  6.363400e+09  2.050331e+08  4.203330e+08   \n",
       "max    9.850332e+10  1.030000e+11  6.403559e+10  9.144171e+09  8.686380e+09   \n",
       "\n",
       "       ...  receivableL2         debt2  liquidLiabilities2    shortLoan2  \\\n",
       "count  ...  2.930000e+02  2.930000e+02        2.930000e+02  2.930000e+02   \n",
       "mean   ...  2.226700e+05  8.146026e+09        3.860584e+09  1.510050e+09   \n",
       "std    ...  3.811496e+06  1.255800e+10        6.797242e+09  2.953412e+09   \n",
       "min    ...  0.000000e+00  0.000000e+00        0.000000e+00  0.000000e+00   \n",
       "25%    ...  0.000000e+00  1.283220e+09        2.855741e+08  0.000000e+00   \n",
       "50%    ...  0.000000e+00  3.784553e+09        1.454050e+09  8.542549e+07   \n",
       "75%    ...  0.000000e+00  8.465053e+09        4.364714e+09  1.567967e+09   \n",
       "max    ...  6.524231e+07  8.508858e+10        6.846878e+10  1.759375e+10   \n",
       "\n",
       "       NCLiabilities2     longLoan2     netAsset2      surplus2    employee1  \\\n",
       "count    2.930000e+02  2.930000e+02  2.930000e+02  2.930000e+02   291.000000   \n",
       "mean     4.471247e+09  2.709979e+09  5.273919e+09  9.786279e+08   142.546392   \n",
       "std      7.659580e+09  4.564001e+09  1.081259e+10  4.688798e+09   160.191073   \n",
       "min      0.000000e+00  0.000000e+00 -2.014780e+10 -2.781507e+09     0.000000   \n",
       "25%      2.557878e+07  0.000000e+00  1.017573e+09  0.000000e+00    53.500000   \n",
       "50%      1.969747e+09  1.100000e+09  2.894970e+09  0.000000e+00    80.000000   \n",
       "75%      4.905441e+09  3.360000e+09  5.370285e+09  1.014447e+08   181.500000   \n",
       "max      5.150388e+10  3.256147e+10  1.250000e+11  6.852730e+10  1200.000000   \n",
       "\n",
       "         employee2  \n",
       "count   288.000000  \n",
       "mean    134.326389  \n",
       "std     151.061786  \n",
       "min       0.000000  \n",
       "25%      53.750000  \n",
       "50%      79.000000  \n",
       "75%     170.000000  \n",
       "max    1200.000000  \n",
       "\n",
       "[8 rows x 54 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 간단한 통계량 확인하기\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나. 결측치 확인 및 처리<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inst_id                0\n",
      "OC                     0\n",
      "sido                   0\n",
      "sgg                    0\n",
      "openDate               0\n",
      "bedCount               5\n",
      "instkind               1\n",
      "revenue1               8\n",
      "salescost1             8\n",
      "sga1                   8\n",
      "salary1                8\n",
      "noi1                   8\n",
      "noe1                   8\n",
      "interest1              8\n",
      "ctax1                  8\n",
      "profit1                8\n",
      "liquidAsset1           8\n",
      "quickAsset1            8\n",
      "receivableS1           8\n",
      "inventoryAsset1        8\n",
      "nonCAsset1             8\n",
      "tanAsset1              8\n",
      "OnonCAsset1            8\n",
      "receivableL1           8\n",
      "debt1                  8\n",
      "liquidLiabilities1     8\n",
      "shortLoan1             8\n",
      "NCLiabilities1         8\n",
      "longLoan1              8\n",
      "netAsset1              8\n",
      "surplus1               8\n",
      "revenue2               8\n",
      "salescost2             8\n",
      "sga2                   8\n",
      "salary2                8\n",
      "noi2                   8\n",
      "noe2                   8\n",
      "interest2              8\n",
      "ctax2                  8\n",
      "profit2                8\n",
      "liquidAsset2           8\n",
      "quickAsset2            8\n",
      "receivableS2           8\n",
      "inventoryAsset2        8\n",
      "nonCAsset2             8\n",
      "tanAsset2              8\n",
      "OnonCAsset2            8\n",
      "receivableL2           8\n",
      "debt2                  8\n",
      "liquidLiabilities2     8\n",
      "shortLoan2             8\n",
      "NCLiabilities2         8\n",
      "longLoan2              8\n",
      "netAsset2              8\n",
      "surplus2               8\n",
      "employee1             10\n",
      "employee2             13\n",
      "ownerChange           12\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Na값 , null 값 등 결측치 확인하기\n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(data,numeric,categoric):\n",
    "    # OC칼럼에 close 앞에 공백이 있는데 이를 제거해준다.\n",
    "    data['OC'] = data['OC'].str.strip()\n",
    "    \n",
    "    # Null값이 없는 데이터들만을 모아 병원규모 별로 평균값을 낸다.\n",
    "    non_null_data = data.dropna(axis=0)\n",
    "    grouped_data = non_null_data.groupby('instkind').mean()\n",
    "\n",
    "    # Null값이 존재하는 행의 인덱스들만을 모아본다.\n",
    "    na_list = []\n",
    "    for col in data.columns:\n",
    "        for idx in list(data[data[col].isna()].index):\n",
    "            na_list.append(idx)\n",
    "    \n",
    "    # 집합을 이용하여 중복제거\n",
    "    isNullList = sorted(list(set(na_list)))\n",
    "\n",
    "    # 데이터를 한 행씩 읽어 나가면서 null값이나 누락값을 가진 속성이 존재하면 같은 동급 병원규모에 해당하는 데이터들의 평균값으로 채워 넣는다.\n",
    "    for idx,item in data.iloc[isNullList,:].iterrows():\n",
    "        for col in grouped_data.columns:\n",
    "            if str(item[col]) in ['nan', '0','0.0'] and idx!=193:\n",
    "                data.loc[idx,col] = grouped_data.loc[data.loc[idx,:].instkind,col]\n",
    "\n",
    "    # 193번 데이터는 병원 종류와 병상수 모두 Null값으로 존재한다. 삭제를 선택\n",
    "    data.drop(193,inplace=True)\n",
    "    data.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    # NaN 값을 제외한 ownerChange 칼럼의 값을 0,1로 인코딩한다.\n",
    "    data['ownerChange'] = np.where(data['ownerChange']=='change',1,np.where(data['ownerChange']=='same',0,np.NaN))\n",
    "    for col in categoric_data:\n",
    "            data[col] = data[col].astype('category').cat.codes\n",
    "            data[col] = data[col].astype('int')\n",
    "\n",
    "    # KNN알고리즘을 이용해 ownerChange 칼럼이 NaN값인 데이터의 값을 가장 유사한 데이터의 값으로 채워 넣는다.\n",
    "    imputer = KNNImputer(n_neighbors=1)\n",
    "    tmp = pd.DataFrame(imputer.fit_transform(data))\n",
    "\n",
    "    # 칼럼명을 다시 설정\n",
    "    tmp.columns = data.columns\n",
    "    data = tmp\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_cleaning(data,*split_num_cat(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다. 데이터 탐색 및 Feature Selection<br>\n",
    "\n",
    "데이터를 탐색하고 데이터의 특성을 파악한다.\n",
    "파생변수를 생성하고 그 후 학습에 사용할 중요한 속성을 선택한다.<br>\n",
    "\n",
    "사용할 방식<br>\n",
    "재무재표 분석 : 속성 중 비용과 법인세등 서로 종속적인 속성이 많이 존재한다. 이를 통해 종속적인 속성을 drop함으로 써 불필요한 속성을 줄여나간다.<br>\n",
    "상관관계 분석 : 상관계수를 구하고 상관계수의 절댓값이 높은 칼럼 조합을 통해서 변수를 조금 더 단순하게 바꿔본다.<br>\n",
    "주성분 분석(PCA) : 다중 속성을 좀 더 작은 차원의 주성분으로 새로운 데이터를 만들어내는 것이다.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 속성 중 비용과 법인세등 서로 종속적인 속성이 많이 존재한다. 이를 통해 종속적인 속성을 drop함으로 써 불필요한 속성을 줄여나간다.\n",
    "# 똑같은 칼럼이 2017년 2016년 이 서로 같은 이름에 1,2로 달리 존재하므로 이를 통해 칼럼을 줄인다.\n",
    "derived  = ['revenue', 'salescost', 'sga', 'salary', 'noi', 'noe', 'interest', 'ctax', 'profit', 'liquidAsset', 'quickAsset', 'receivableS', 'inventoryAsset', \n",
    "'nonCAsset', 'tanAsset','OnonCAsset', 'receivableL', 'debt', 'liquidLiabilities','shortLoan', 'NCLiabilities', 'longLoan', 'netAsset', 'surplus','employee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select_cols(data,cols) -> DataFrame\n",
    "# inputs\n",
    "## data : 데이터프레임\n",
    "## cols : 선택할 속성명\n",
    "# output\n",
    "## DataFrame\n",
    "def select_cols(data,cols):\n",
    "    return data.loc[:,cols]\n",
    "\n",
    "# make_derivate(data,cols) -> derivated\n",
    "# inputs\n",
    "## data : 데이터프레임 (Null 값이 없는 정제된 값)\n",
    "## cols : 속성명 2017년도 - 206년도 할 속성명\n",
    "# output\n",
    "## derivated : 유도된 속성들과 기존 필수 칼럼들을 가지고 있는 데이터 프레임\n",
    "def make_derivate(data,cols):\n",
    "    derivated = pd.DataFrame()\n",
    "    necessary = ['sido','instkind']\n",
    "    pre_data = pd.get_dummies(data[['sido','instkind']].astype('str'))\n",
    "    for col in cols:\n",
    "        derivated[col+'_diff'] = data[col+'1'] - data[col+'2']\n",
    "    derivated['OC'] = data['OC']\n",
    "    return pd.concat([pre_data,derivated],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sido_0.0</th>\n",
       "      <th>sido_1.0</th>\n",
       "      <th>sido_10.0</th>\n",
       "      <th>sido_11.0</th>\n",
       "      <th>sido_12.0</th>\n",
       "      <th>sido_13.0</th>\n",
       "      <th>sido_14.0</th>\n",
       "      <th>sido_15.0</th>\n",
       "      <th>sido_2.0</th>\n",
       "      <th>sido_3.0</th>\n",
       "      <th>...</th>\n",
       "      <th>noi_diff</th>\n",
       "      <th>salescost_diff</th>\n",
       "      <th>sga_diff</th>\n",
       "      <th>noe_diff</th>\n",
       "      <th>ctax_diff</th>\n",
       "      <th>liquidLiabilities_diff</th>\n",
       "      <th>NCLiabilities_diff</th>\n",
       "      <th>liquidAsset_diff</th>\n",
       "      <th>nonCAsset_diff</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.422340e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.628707e+07</td>\n",
       "      <td>-1.474712e+07</td>\n",
       "      <td>1.283372e+07</td>\n",
       "      <td>-2.155316e+07</td>\n",
       "      <td>-5.461460e+07</td>\n",
       "      <td>1.825302e+08</td>\n",
       "      <td>-3.352830e+07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.238722e+08</td>\n",
       "      <td>1.933420e+08</td>\n",
       "      <td>3.466290e+09</td>\n",
       "      <td>-1.315082e+08</td>\n",
       "      <td>2.127925e+07</td>\n",
       "      <td>8.240150e+08</td>\n",
       "      <td>1.949935e+09</td>\n",
       "      <td>5.150572e+08</td>\n",
       "      <td>2.491472e+09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.615600e+04</td>\n",
       "      <td>5.154837e+08</td>\n",
       "      <td>4.472197e+08</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.241434e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.724421e+08</td>\n",
       "      <td>1.204810e+08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.941526e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.753205e+09</td>\n",
       "      <td>-9.410484e+07</td>\n",
       "      <td>-4.512194e+07</td>\n",
       "      <td>1.097328e+10</td>\n",
       "      <td>-6.364497e+09</td>\n",
       "      <td>1.915823e+09</td>\n",
       "      <td>3.595795e+09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.853959e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.302526e+08</td>\n",
       "      <td>-1.030186e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.163398e+09</td>\n",
       "      <td>-3.710896e+08</td>\n",
       "      <td>1.410308e+09</td>\n",
       "      <td>-2.864045e+09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.821919e+07</td>\n",
       "      <td>9.562002e+06</td>\n",
       "      <td>-8.520281e+08</td>\n",
       "      <td>5.349343e+08</td>\n",
       "      <td>-5.160864e+07</td>\n",
       "      <td>-1.098198e+09</td>\n",
       "      <td>3.897958e+08</td>\n",
       "      <td>2.260411e+08</td>\n",
       "      <td>-3.400561e+08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.386063e+08</td>\n",
       "      <td>6.672417e+09</td>\n",
       "      <td>1.274022e+09</td>\n",
       "      <td>-5.950085e+08</td>\n",
       "      <td>2.866089e+07</td>\n",
       "      <td>3.358350e+08</td>\n",
       "      <td>-4.113762e+08</td>\n",
       "      <td>3.183131e+08</td>\n",
       "      <td>9.233064e+08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.218987e+07</td>\n",
       "      <td>-1.293421e+09</td>\n",
       "      <td>-2.981850e+08</td>\n",
       "      <td>4.916528e+06</td>\n",
       "      <td>2.866089e+07</td>\n",
       "      <td>-1.206310e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.073841e+08</td>\n",
       "      <td>1.500000e+07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.131200e+08</td>\n",
       "      <td>-2.180236e+08</td>\n",
       "      <td>-1.464406e+09</td>\n",
       "      <td>-1.063551e+09</td>\n",
       "      <td>6.461230e+06</td>\n",
       "      <td>1.107060e+09</td>\n",
       "      <td>8.339939e+06</td>\n",
       "      <td>-9.666775e+08</td>\n",
       "      <td>-1.008900e+07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.037922e+06</td>\n",
       "      <td>-2.195647e+07</td>\n",
       "      <td>-2.112054e+07</td>\n",
       "      <td>-2.083541e+07</td>\n",
       "      <td>3.543340e+07</td>\n",
       "      <td>6.454699e+07</td>\n",
       "      <td>5.000000e+06</td>\n",
       "      <td>1.654563e+08</td>\n",
       "      <td>-1.414186e+08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sido_0.0  sido_1.0  sido_10.0  sido_11.0  sido_12.0  sido_13.0  \\\n",
       "0           0         0          0          0          0          0   \n",
       "1           0         0          0          0          0          0   \n",
       "2           0         0          0          0          0          0   \n",
       "3           0         0          1          0          0          0   \n",
       "4           0         0          0          0          0          0   \n",
       "..        ...       ...        ...        ...        ...        ...   \n",
       "295         0         0          0          0          1          0   \n",
       "296         0         0          0          0          0          0   \n",
       "297         0         0          0          0          0          0   \n",
       "298         0         0          0          0          0          0   \n",
       "299         0         0          0          0          0          0   \n",
       "\n",
       "     sido_14.0  sido_15.0  sido_2.0  sido_3.0  ...      noi_diff  \\\n",
       "0            0          0         1         0  ... -5.422340e+05   \n",
       "1            0          0         0         0  ...  1.238722e+08   \n",
       "2            0          0         0         0  ...  7.615600e+04   \n",
       "3            0          0         0         0  ...  2.941526e+07   \n",
       "4            0          0         0         0  ... -4.853959e+08   \n",
       "..         ...        ...       ...       ...  ...           ...   \n",
       "295          0          0         0         0  ... -4.821919e+07   \n",
       "296          0          0         1         0  ... -2.386063e+08   \n",
       "297          0          0         0         0  ... -5.218987e+07   \n",
       "298          0          0         0         0  ...  1.131200e+08   \n",
       "299          1          0         0         0  ... -2.037922e+06   \n",
       "\n",
       "     salescost_diff      sga_diff      noe_diff     ctax_diff  \\\n",
       "0      0.000000e+00 -9.628707e+07 -1.474712e+07  1.283372e+07   \n",
       "1      1.933420e+08  3.466290e+09 -1.315082e+08  2.127925e+07   \n",
       "2      5.154837e+08  4.472197e+08  3.000000e+04  0.000000e+00   \n",
       "3      0.000000e+00  5.753205e+09 -9.410484e+07 -4.512194e+07   \n",
       "4      0.000000e+00  5.302526e+08 -1.030186e+08  0.000000e+00   \n",
       "..              ...           ...           ...           ...   \n",
       "295    9.562002e+06 -8.520281e+08  5.349343e+08 -5.160864e+07   \n",
       "296    6.672417e+09  1.274022e+09 -5.950085e+08  2.866089e+07   \n",
       "297   -1.293421e+09 -2.981850e+08  4.916528e+06  2.866089e+07   \n",
       "298   -2.180236e+08 -1.464406e+09 -1.063551e+09  6.461230e+06   \n",
       "299   -2.195647e+07 -2.112054e+07 -2.083541e+07  3.543340e+07   \n",
       "\n",
       "     liquidLiabilities_diff  NCLiabilities_diff  liquidAsset_diff  \\\n",
       "0             -2.155316e+07       -5.461460e+07      1.825302e+08   \n",
       "1              8.240150e+08        1.949935e+09      5.150572e+08   \n",
       "2              9.241434e+07        0.000000e+00      2.724421e+08   \n",
       "3              1.097328e+10       -6.364497e+09      1.915823e+09   \n",
       "4             -1.163398e+09       -3.710896e+08      1.410308e+09   \n",
       "..                      ...                 ...               ...   \n",
       "295           -1.098198e+09        3.897958e+08      2.260411e+08   \n",
       "296            3.358350e+08       -4.113762e+08      3.183131e+08   \n",
       "297           -1.206310e+08        0.000000e+00     -2.073841e+08   \n",
       "298            1.107060e+09        8.339939e+06     -9.666775e+08   \n",
       "299            6.454699e+07        5.000000e+06      1.654563e+08   \n",
       "\n",
       "     nonCAsset_diff   OC  \n",
       "0     -3.352830e+07  1.0  \n",
       "1      2.491472e+09  1.0  \n",
       "2      1.204810e+08  1.0  \n",
       "3      3.595795e+09  1.0  \n",
       "4     -2.864045e+09  1.0  \n",
       "..              ...  ...  \n",
       "295   -3.400561e+08  1.0  \n",
       "296    9.233064e+08  0.0  \n",
       "297    1.500000e+07  0.0  \n",
       "298   -1.008900e+07  0.0  \n",
       "299   -1.414186e+08  1.0  \n",
       "\n",
       "[300 rows x 34 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cols : 실제로 다른 칼럼들을 포함하는 변수들 중 대표가되는 칼럼들을 선택\n",
    "cols = ['revenue','noi','salescost','sga','noe','ctax','liquidLiabilities','NCLiabilities','liquidAsset','nonCAsset']\n",
    "data = make_derivate(data,cols)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19ff7f5db234aa98d66bc19851e538a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(ToggleButtons(_dom_classes=('layout-dd07a965fc1441de8fc0a702106c57ef',), description='Selection…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VisualAnalysis(data,\n",
    "    layout=[[\"Scatter\", \"Scatter\"],\n",
    "            [\"BoxPlot\", 'Histogram']],\n",
    "               row_height=[250, 500]   # 인터페이스 전체 넓이 및 높이 지정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip_outlier(inst_num_data) -> result <이상치가 clip된 데이터프레임>\n",
    "# input\n",
    "## inst_num_data : DataFrame\n",
    "# output\n",
    "## result :  Clipped DataFrame\n",
    "def clip_outlier(inst_num_data,min_max = 'default'):\n",
    "    # min_max {'default': 'min_ = first_IQR, max_ = third_IQR',\n",
    "    #          'min_max': 'min_ = inst_num_data[col].min(), max_ = inst_num_data[col].max()' }\n",
    "    #over = []\n",
    "    r_inst_num_data = pd.DataFrame() # 이상치 변경 데이터프레임 생성할 것\n",
    "    numeric = []\n",
    "    non_numeric = []\n",
    "    for col in inst_num_data.columns:\n",
    "        if 'diff' in col:\n",
    "            numeric.append(col)\n",
    "        else:\n",
    "            non_numeric.append(col)\n",
    "    non_numeric_data = inst_num_data[non_numeric]\n",
    "\n",
    "    for col in numeric:\n",
    "        # IQR 이용 : IQR= [제 3사분위수] - [제 1사분위수]\n",
    "        first = np.percentile(inst_num_data[col], 25, interpolation='nearest') # 제 1사분위수\n",
    "        third = np.percentile(inst_num_data[col], 75, interpolation='nearest') # 제 3사분위수\n",
    "        IQR = third - first\n",
    "        \n",
    "        # 제 1사분위수보다 1.5IQR이상 작거나 제 3사분위수보다 1.5IQR이상 큰 값들을 이상치로 구분\n",
    "        first_IQR = first-IQR*1.5\n",
    "        third_IQR = third+IQR*1.5\n",
    "\n",
    "        min_ = first_IQR\n",
    "        max_ = third_IQR\n",
    "        \n",
    "        if min_max == 'min_max':\n",
    "            min_ = inst_num_data[col].min()\n",
    "            max_ = inst_num_data[col].max()\n",
    "\n",
    "\n",
    "        # 이상치 인덱스 및 값을 저장\n",
    "        up_idx = (inst_num_data[inst_num_data[col] > third_IQR].index)\n",
    "        down_idx = (inst_num_data[inst_num_data[col] < first_IQR].index)\n",
    "        up_val = list(inst_num_data.loc[up_idx,col])\n",
    "        down_val = list(inst_num_data.loc[down_idx,col])\n",
    "\n",
    "        # 이상치 개수\n",
    "        up_over = inst_num_data[inst_num_data[col] > third_IQR].shape[0]\n",
    "        down_over = inst_num_data[inst_num_data[col] < first_IQR].shape[0]\n",
    "        \n",
    "        # np.clip 이상치를 주변 대푯값(min,max)으로 바꾸기\n",
    "        # min과 max 값을 바꾸어 \n",
    "        num_array = inst_num_data[col].array\n",
    "        r_inst_num_data[col] = np.clip(num_array, min_, max_) # numpy.clip(array, min, max)\n",
    "\n",
    "    result = pd.DataFrame(np.c_[np.array(non_numeric_data),np.array(r_inst_num_data)])\n",
    "    result.columns = non_numeric + numeric\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sido_0.0</th>\n",
       "      <th>sido_1.0</th>\n",
       "      <th>sido_10.0</th>\n",
       "      <th>sido_11.0</th>\n",
       "      <th>sido_12.0</th>\n",
       "      <th>sido_13.0</th>\n",
       "      <th>sido_14.0</th>\n",
       "      <th>sido_15.0</th>\n",
       "      <th>sido_2.0</th>\n",
       "      <th>sido_3.0</th>\n",
       "      <th>...</th>\n",
       "      <th>revenue_diff</th>\n",
       "      <th>noi_diff</th>\n",
       "      <th>salescost_diff</th>\n",
       "      <th>sga_diff</th>\n",
       "      <th>noe_diff</th>\n",
       "      <th>ctax_diff</th>\n",
       "      <th>liquidLiabilities_diff</th>\n",
       "      <th>NCLiabilities_diff</th>\n",
       "      <th>liquidAsset_diff</th>\n",
       "      <th>nonCAsset_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.031824e+07</td>\n",
       "      <td>-5.422340e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.628707e+07</td>\n",
       "      <td>-1.474712e+07</td>\n",
       "      <td>1.283372e+07</td>\n",
       "      <td>-2.155316e+07</td>\n",
       "      <td>-5.461460e+07</td>\n",
       "      <td>1.825302e+08</td>\n",
       "      <td>-3.352830e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.264545e+09</td>\n",
       "      <td>1.238722e+08</td>\n",
       "      <td>1.933420e+08</td>\n",
       "      <td>3.466290e+09</td>\n",
       "      <td>-1.315082e+08</td>\n",
       "      <td>2.127925e+07</td>\n",
       "      <td>8.240150e+08</td>\n",
       "      <td>1.949935e+09</td>\n",
       "      <td>5.150572e+08</td>\n",
       "      <td>2.491472e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004522e+09</td>\n",
       "      <td>7.615600e+04</td>\n",
       "      <td>5.154837e+08</td>\n",
       "      <td>4.472197e+08</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.241434e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.724421e+08</td>\n",
       "      <td>1.204810e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.649006e+09</td>\n",
       "      <td>2.941526e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.753205e+09</td>\n",
       "      <td>-9.410484e+07</td>\n",
       "      <td>-4.512194e+07</td>\n",
       "      <td>1.097328e+10</td>\n",
       "      <td>-6.364497e+09</td>\n",
       "      <td>1.915823e+09</td>\n",
       "      <td>3.595795e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.607370e+08</td>\n",
       "      <td>-4.853959e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.302526e+08</td>\n",
       "      <td>-1.030186e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.163398e+09</td>\n",
       "      <td>-3.710896e+08</td>\n",
       "      <td>1.410308e+09</td>\n",
       "      <td>-2.864045e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.539098e+08</td>\n",
       "      <td>-6.026683e+07</td>\n",
       "      <td>-6.161420e+08</td>\n",
       "      <td>-3.683077e+08</td>\n",
       "      <td>2.911864e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.361751e+09</td>\n",
       "      <td>-2.000000e+07</td>\n",
       "      <td>7.656857e+08</td>\n",
       "      <td>-3.477443e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.117334e+09</td>\n",
       "      <td>8.306136e+07</td>\n",
       "      <td>-3.148806e+08</td>\n",
       "      <td>1.260974e+09</td>\n",
       "      <td>-5.064204e+07</td>\n",
       "      <td>-7.693937e+07</td>\n",
       "      <td>7.056978e+09</td>\n",
       "      <td>-2.576700e+09</td>\n",
       "      <td>3.610923e+08</td>\n",
       "      <td>-3.516812e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.862735e+09</td>\n",
       "      <td>-3.695702e+08</td>\n",
       "      <td>1.175437e+09</td>\n",
       "      <td>1.437995e+09</td>\n",
       "      <td>2.245827e+09</td>\n",
       "      <td>3.125135e+08</td>\n",
       "      <td>1.434358e+10</td>\n",
       "      <td>-3.442379e+09</td>\n",
       "      <td>4.074534e+09</td>\n",
       "      <td>-2.928085e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.620741e+07</td>\n",
       "      <td>1.956999e+08</td>\n",
       "      <td>-2.112083e+07</td>\n",
       "      <td>6.631265e+07</td>\n",
       "      <td>-2.492024e+08</td>\n",
       "      <td>9.989394e+07</td>\n",
       "      <td>-1.554118e+09</td>\n",
       "      <td>-2.078189e+07</td>\n",
       "      <td>1.017168e+09</td>\n",
       "      <td>-1.557324e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.575352e+09</td>\n",
       "      <td>4.661253e+08</td>\n",
       "      <td>-7.641224e+08</td>\n",
       "      <td>-4.288000e+08</td>\n",
       "      <td>-1.754577e+09</td>\n",
       "      <td>-9.153942e+07</td>\n",
       "      <td>-3.021292e+09</td>\n",
       "      <td>-1.351110e+09</td>\n",
       "      <td>4.977253e+08</td>\n",
       "      <td>-5.388727e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.179161e+09</td>\n",
       "      <td>7.850452e+07</td>\n",
       "      <td>8.605428e+08</td>\n",
       "      <td>2.021246e+09</td>\n",
       "      <td>2.732504e+08</td>\n",
       "      <td>-1.060353e+07</td>\n",
       "      <td>-3.028654e+09</td>\n",
       "      <td>4.623728e+09</td>\n",
       "      <td>-1.402933e+09</td>\n",
       "      <td>9.163816e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.481993e+10</td>\n",
       "      <td>2.727323e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.433499e+10</td>\n",
       "      <td>3.100628e+08</td>\n",
       "      <td>2.520527e+08</td>\n",
       "      <td>1.298759e+10</td>\n",
       "      <td>5.000000e+06</td>\n",
       "      <td>3.921155e+09</td>\n",
       "      <td>1.560308e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.052322e+08</td>\n",
       "      <td>7.540700e+04</td>\n",
       "      <td>-1.058951e+07</td>\n",
       "      <td>3.319659e+07</td>\n",
       "      <td>1.656151e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.614708e+09</td>\n",
       "      <td>-7.306834e+09</td>\n",
       "      <td>3.530453e+08</td>\n",
       "      <td>-6.135085e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.827653e+09</td>\n",
       "      <td>1.408820e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.143809e+09</td>\n",
       "      <td>1.105674e+08</td>\n",
       "      <td>-9.708174e+07</td>\n",
       "      <td>5.608239e+09</td>\n",
       "      <td>-5.595750e+09</td>\n",
       "      <td>1.987967e+09</td>\n",
       "      <td>-4.192872e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.264545e+09</td>\n",
       "      <td>1.238722e+08</td>\n",
       "      <td>1.933420e+08</td>\n",
       "      <td>3.466290e+09</td>\n",
       "      <td>-1.315082e+08</td>\n",
       "      <td>2.127925e+07</td>\n",
       "      <td>8.240150e+08</td>\n",
       "      <td>1.949935e+09</td>\n",
       "      <td>5.150572e+08</td>\n",
       "      <td>2.491472e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.800000e+10</td>\n",
       "      <td>3.680216e+07</td>\n",
       "      <td>4.204416e+09</td>\n",
       "      <td>1.332890e+10</td>\n",
       "      <td>6.067790e+07</td>\n",
       "      <td>-4.770136e+08</td>\n",
       "      <td>2.563214e+09</td>\n",
       "      <td>4.808121e+08</td>\n",
       "      <td>-2.667126e+08</td>\n",
       "      <td>-4.430786e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004121e+09</td>\n",
       "      <td>2.313429e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.021683e+09</td>\n",
       "      <td>1.778740e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.111570e+09</td>\n",
       "      <td>1.670076e+09</td>\n",
       "      <td>-1.507550e+08</td>\n",
       "      <td>-1.253912e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.694804e+09</td>\n",
       "      <td>8.536571e+06</td>\n",
       "      <td>-6.164740e+07</td>\n",
       "      <td>2.342941e+09</td>\n",
       "      <td>4.002406e+08</td>\n",
       "      <td>-4.387374e+07</td>\n",
       "      <td>1.611663e+09</td>\n",
       "      <td>1.010572e+10</td>\n",
       "      <td>-5.776283e+08</td>\n",
       "      <td>1.269222e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.289816e+09</td>\n",
       "      <td>-1.630674e+07</td>\n",
       "      <td>1.039144e+08</td>\n",
       "      <td>2.225998e+09</td>\n",
       "      <td>1.688195e+08</td>\n",
       "      <td>2.039852e+07</td>\n",
       "      <td>-4.380501e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.226137e+08</td>\n",
       "      <td>-4.334371e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.468689e+08</td>\n",
       "      <td>1.253031e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.697114e+09</td>\n",
       "      <td>6.136076e+08</td>\n",
       "      <td>7.194771e+07</td>\n",
       "      <td>-7.986452e+08</td>\n",
       "      <td>5.885586e+08</td>\n",
       "      <td>2.449931e+09</td>\n",
       "      <td>1.036793e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.194046e+08</td>\n",
       "      <td>7.626808e+06</td>\n",
       "      <td>-2.984320e+07</td>\n",
       "      <td>-4.550491e+07</td>\n",
       "      <td>-3.507788e+07</td>\n",
       "      <td>-4.680331e+07</td>\n",
       "      <td>4.435093e+08</td>\n",
       "      <td>2.497021e+08</td>\n",
       "      <td>-7.104766e+08</td>\n",
       "      <td>-1.329791e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.362445e+09</td>\n",
       "      <td>5.547592e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.155799e+09</td>\n",
       "      <td>-3.059546e+08</td>\n",
       "      <td>5.093487e+07</td>\n",
       "      <td>-3.057342e+10</td>\n",
       "      <td>3.218209e+10</td>\n",
       "      <td>8.675431e+08</td>\n",
       "      <td>1.000000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.493230e+09</td>\n",
       "      <td>-2.671204e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-6.714294e+08</td>\n",
       "      <td>2.304936e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.124797e+09</td>\n",
       "      <td>-5.565883e+08</td>\n",
       "      <td>-1.692620e+08</td>\n",
       "      <td>-5.891485e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.008439e+09</td>\n",
       "      <td>5.548792e+06</td>\n",
       "      <td>1.582195e+08</td>\n",
       "      <td>1.749903e+09</td>\n",
       "      <td>-8.632789e+06</td>\n",
       "      <td>2.312962e+08</td>\n",
       "      <td>7.973576e+09</td>\n",
       "      <td>-7.584602e+09</td>\n",
       "      <td>1.325941e+08</td>\n",
       "      <td>-1.149764e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.589705e+08</td>\n",
       "      <td>3.084087e+07</td>\n",
       "      <td>2.674466e+08</td>\n",
       "      <td>1.093228e+08</td>\n",
       "      <td>-2.305366e+08</td>\n",
       "      <td>5.038750e+06</td>\n",
       "      <td>-4.015136e+08</td>\n",
       "      <td>2.492367e+08</td>\n",
       "      <td>5.530263e+08</td>\n",
       "      <td>-3.086150e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.528603e+08</td>\n",
       "      <td>-3.600173e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.709094e+08</td>\n",
       "      <td>-3.003377e+07</td>\n",
       "      <td>-2.635150e+06</td>\n",
       "      <td>6.474172e+09</td>\n",
       "      <td>-6.245766e+09</td>\n",
       "      <td>1.685077e+08</td>\n",
       "      <td>-1.128163e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.390813e+09</td>\n",
       "      <td>-3.221720e+07</td>\n",
       "      <td>3.461275e+08</td>\n",
       "      <td>8.622938e+08</td>\n",
       "      <td>-2.680180e+08</td>\n",
       "      <td>1.608712e+08</td>\n",
       "      <td>-1.698772e+09</td>\n",
       "      <td>4.740761e+08</td>\n",
       "      <td>2.000495e+08</td>\n",
       "      <td>1.238243e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.665210e+08</td>\n",
       "      <td>1.938326e+07</td>\n",
       "      <td>-7.406316e+07</td>\n",
       "      <td>4.821585e+08</td>\n",
       "      <td>8.104319e+07</td>\n",
       "      <td>-2.362370e+06</td>\n",
       "      <td>2.549574e+09</td>\n",
       "      <td>3.698003e+09</td>\n",
       "      <td>5.825841e+07</td>\n",
       "      <td>6.299221e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.525499e+09</td>\n",
       "      <td>1.321572e+08</td>\n",
       "      <td>1.774126e+09</td>\n",
       "      <td>3.946157e+09</td>\n",
       "      <td>-2.495252e+09</td>\n",
       "      <td>3.861690e+08</td>\n",
       "      <td>-1.784517e+09</td>\n",
       "      <td>-2.526266e+09</td>\n",
       "      <td>-1.055146e+09</td>\n",
       "      <td>-1.527025e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.493173e+08</td>\n",
       "      <td>-5.299606e+07</td>\n",
       "      <td>1.831953e+07</td>\n",
       "      <td>-1.242649e+08</td>\n",
       "      <td>-7.415947e+08</td>\n",
       "      <td>1.789237e+08</td>\n",
       "      <td>-1.651783e+09</td>\n",
       "      <td>-5.000000e+08</td>\n",
       "      <td>5.803394e+08</td>\n",
       "      <td>-1.383835e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sido_0.0  sido_1.0  sido_10.0  sido_11.0  sido_12.0  sido_13.0  sido_14.0  \\\n",
       "0        0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1        0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3        0.0       0.0        1.0        0.0        0.0        0.0        0.0   \n",
       "4        0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "5        0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "6        0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "7        1.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "8        0.0       0.0        0.0        0.0        1.0        0.0        0.0   \n",
       "9        0.0       0.0        0.0        0.0        0.0        0.0        1.0   \n",
       "10       0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "11       0.0       0.0        0.0        1.0        0.0        0.0        0.0   \n",
       "12       0.0       1.0        0.0        0.0        0.0        0.0        0.0   \n",
       "13       0.0       0.0        1.0        0.0        0.0        0.0        0.0   \n",
       "14       0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "15       0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "16       0.0       0.0        0.0        0.0        0.0        0.0        1.0   \n",
       "17       0.0       0.0        1.0        0.0        0.0        0.0        0.0   \n",
       "18       0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "19       0.0       0.0        0.0        0.0        0.0        0.0        1.0   \n",
       "20       0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "21       0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "22       0.0       0.0        0.0        0.0        0.0        0.0        1.0   \n",
       "23       0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "24       0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "25       0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "26       0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "27       0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "28       0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "29       0.0       0.0        0.0        0.0        0.0        0.0        1.0   \n",
       "\n",
       "    sido_15.0  sido_2.0  sido_3.0  ...  revenue_diff      noi_diff  \\\n",
       "0         0.0       1.0       0.0  ... -8.031824e+07 -5.422340e+05   \n",
       "1         0.0       0.0       0.0  ...  3.264545e+09  1.238722e+08   \n",
       "2         0.0       0.0       0.0  ...  1.004522e+09  7.615600e+04   \n",
       "3         0.0       0.0       0.0  ...  5.649006e+09  2.941526e+07   \n",
       "4         0.0       0.0       0.0  ...  9.607370e+08 -4.853959e+08   \n",
       "5         0.0       0.0       0.0  ... -7.539098e+08 -6.026683e+07   \n",
       "6         0.0       0.0       0.0  ...  1.117334e+09  8.306136e+07   \n",
       "7         0.0       0.0       0.0  ...  4.862735e+09 -3.695702e+08   \n",
       "8         0.0       0.0       0.0  ... -7.620741e+07  1.956999e+08   \n",
       "9         0.0       0.0       0.0  ... -4.575352e+09  4.661253e+08   \n",
       "10        0.0       0.0       0.0  ...  3.179161e+09  7.850452e+07   \n",
       "11        0.0       0.0       0.0  ...  1.481993e+10  2.727323e+08   \n",
       "12        0.0       0.0       0.0  ...  1.052322e+08  7.540700e+04   \n",
       "13        0.0       0.0       0.0  ...  3.827653e+09  1.408820e+08   \n",
       "14        1.0       0.0       0.0  ...  3.264545e+09  1.238722e+08   \n",
       "15        1.0       0.0       0.0  ...  1.800000e+10  3.680216e+07   \n",
       "16        0.0       0.0       0.0  ...  1.004121e+09  2.313429e+08   \n",
       "17        0.0       0.0       0.0  ...  2.694804e+09  8.536571e+06   \n",
       "18        0.0       0.0       0.0  ...  2.289816e+09 -1.630674e+07   \n",
       "19        0.0       0.0       0.0  ...  9.468689e+08  1.253031e+09   \n",
       "20        0.0       0.0       1.0  ... -2.194046e+08  7.626808e+06   \n",
       "21        0.0       0.0       0.0  ...  1.362445e+09  5.547592e+08   \n",
       "22        0.0       0.0       0.0  ... -1.493230e+09 -2.671204e+07   \n",
       "23        0.0       0.0       1.0  ...  2.008439e+09  5.548792e+06   \n",
       "24        0.0       0.0       0.0  ...  1.589705e+08  3.084087e+07   \n",
       "25        0.0       0.0       0.0  ...  4.528603e+08 -3.600173e+07   \n",
       "26        0.0       0.0       1.0  ...  2.390813e+09 -3.221720e+07   \n",
       "27        0.0       0.0       0.0  ...  4.665210e+08  1.938326e+07   \n",
       "28        0.0       0.0       0.0  ...  2.525499e+09  1.321572e+08   \n",
       "29        0.0       0.0       0.0  ... -6.493173e+08 -5.299606e+07   \n",
       "\n",
       "    salescost_diff      sga_diff      noe_diff     ctax_diff  \\\n",
       "0     0.000000e+00 -9.628707e+07 -1.474712e+07  1.283372e+07   \n",
       "1     1.933420e+08  3.466290e+09 -1.315082e+08  2.127925e+07   \n",
       "2     5.154837e+08  4.472197e+08  3.000000e+04  0.000000e+00   \n",
       "3     0.000000e+00  5.753205e+09 -9.410484e+07 -4.512194e+07   \n",
       "4     0.000000e+00  5.302526e+08 -1.030186e+08  0.000000e+00   \n",
       "5    -6.161420e+08 -3.683077e+08  2.911864e+08  0.000000e+00   \n",
       "6    -3.148806e+08  1.260974e+09 -5.064204e+07 -7.693937e+07   \n",
       "7     1.175437e+09  1.437995e+09  2.245827e+09  3.125135e+08   \n",
       "8    -2.112083e+07  6.631265e+07 -2.492024e+08  9.989394e+07   \n",
       "9    -7.641224e+08 -4.288000e+08 -1.754577e+09 -9.153942e+07   \n",
       "10    8.605428e+08  2.021246e+09  2.732504e+08 -1.060353e+07   \n",
       "11    0.000000e+00  1.433499e+10  3.100628e+08  2.520527e+08   \n",
       "12   -1.058951e+07  3.319659e+07  1.656151e+08  0.000000e+00   \n",
       "13    0.000000e+00  5.143809e+09  1.105674e+08 -9.708174e+07   \n",
       "14    1.933420e+08  3.466290e+09 -1.315082e+08  2.127925e+07   \n",
       "15    4.204416e+09  1.332890e+10  6.067790e+07 -4.770136e+08   \n",
       "16    0.000000e+00  1.021683e+09  1.778740e+09  0.000000e+00   \n",
       "17   -6.164740e+07  2.342941e+09  4.002406e+08 -4.387374e+07   \n",
       "18    1.039144e+08  2.225998e+09  1.688195e+08  2.039852e+07   \n",
       "19    0.000000e+00  1.697114e+09  6.136076e+08  7.194771e+07   \n",
       "20   -2.984320e+07 -4.550491e+07 -3.507788e+07 -4.680331e+07   \n",
       "21    0.000000e+00  3.155799e+09 -3.059546e+08  5.093487e+07   \n",
       "22    0.000000e+00 -6.714294e+08  2.304936e+06  0.000000e+00   \n",
       "23    1.582195e+08  1.749903e+09 -8.632789e+06  2.312962e+08   \n",
       "24    2.674466e+08  1.093228e+08 -2.305366e+08  5.038750e+06   \n",
       "25    0.000000e+00  4.709094e+08 -3.003377e+07 -2.635150e+06   \n",
       "26    3.461275e+08  8.622938e+08 -2.680180e+08  1.608712e+08   \n",
       "27   -7.406316e+07  4.821585e+08  8.104319e+07 -2.362370e+06   \n",
       "28    1.774126e+09  3.946157e+09 -2.495252e+09  3.861690e+08   \n",
       "29    1.831953e+07 -1.242649e+08 -7.415947e+08  1.789237e+08   \n",
       "\n",
       "    liquidLiabilities_diff  NCLiabilities_diff  liquidAsset_diff  \\\n",
       "0            -2.155316e+07       -5.461460e+07      1.825302e+08   \n",
       "1             8.240150e+08        1.949935e+09      5.150572e+08   \n",
       "2             9.241434e+07        0.000000e+00      2.724421e+08   \n",
       "3             1.097328e+10       -6.364497e+09      1.915823e+09   \n",
       "4            -1.163398e+09       -3.710896e+08      1.410308e+09   \n",
       "5            -3.361751e+09       -2.000000e+07      7.656857e+08   \n",
       "6             7.056978e+09       -2.576700e+09      3.610923e+08   \n",
       "7             1.434358e+10       -3.442379e+09      4.074534e+09   \n",
       "8            -1.554118e+09       -2.078189e+07      1.017168e+09   \n",
       "9            -3.021292e+09       -1.351110e+09      4.977253e+08   \n",
       "10           -3.028654e+09        4.623728e+09     -1.402933e+09   \n",
       "11            1.298759e+10        5.000000e+06      3.921155e+09   \n",
       "12            9.614708e+09       -7.306834e+09      3.530453e+08   \n",
       "13            5.608239e+09       -5.595750e+09      1.987967e+09   \n",
       "14            8.240150e+08        1.949935e+09      5.150572e+08   \n",
       "15            2.563214e+09        4.808121e+08     -2.667126e+08   \n",
       "16           -1.111570e+09        1.670076e+09     -1.507550e+08   \n",
       "17            1.611663e+09        1.010572e+10     -5.776283e+08   \n",
       "18           -4.380501e+08        0.000000e+00      3.226137e+08   \n",
       "19           -7.986452e+08        5.885586e+08      2.449931e+09   \n",
       "20            4.435093e+08        2.497021e+08     -7.104766e+08   \n",
       "21           -3.057342e+10        3.218209e+10      8.675431e+08   \n",
       "22            1.124797e+09       -5.565883e+08     -1.692620e+08   \n",
       "23            7.973576e+09       -7.584602e+09      1.325941e+08   \n",
       "24           -4.015136e+08        2.492367e+08      5.530263e+08   \n",
       "25            6.474172e+09       -6.245766e+09      1.685077e+08   \n",
       "26           -1.698772e+09        4.740761e+08      2.000495e+08   \n",
       "27            2.549574e+09        3.698003e+09      5.825841e+07   \n",
       "28           -1.784517e+09       -2.526266e+09     -1.055146e+09   \n",
       "29           -1.651783e+09       -5.000000e+08      5.803394e+08   \n",
       "\n",
       "    nonCAsset_diff  \n",
       "0    -3.352830e+07  \n",
       "1     2.491472e+09  \n",
       "2     1.204810e+08  \n",
       "3     3.595795e+09  \n",
       "4    -2.864045e+09  \n",
       "5    -3.477443e+09  \n",
       "6    -3.516812e+08  \n",
       "7    -2.928085e+09  \n",
       "8    -1.557324e+09  \n",
       "9    -5.388727e+09  \n",
       "10    9.163816e+09  \n",
       "11    1.560308e+10  \n",
       "12   -6.135085e+08  \n",
       "13   -4.192872e+09  \n",
       "14    2.491472e+09  \n",
       "15   -4.430786e+08  \n",
       "16   -1.253912e+09  \n",
       "17    1.269222e+10  \n",
       "18   -4.334371e+08  \n",
       "19    1.036793e+09  \n",
       "20   -1.329791e+08  \n",
       "21    1.000000e+09  \n",
       "22   -5.891485e+07  \n",
       "23   -1.149764e+09  \n",
       "24   -3.086150e+08  \n",
       "25   -1.128163e+09  \n",
       "26    1.238243e+10  \n",
       "27    6.299221e+09  \n",
       "28   -1.527025e+09  \n",
       "29   -1.383835e+09  \n",
       "\n",
       "[30 rows x 34 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = clip_outlier(data,min_max='min_max')\n",
    "data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sclaer(data, method = 'mm') -> scaled_data<DataFrame>:\n",
    "# input\n",
    "## data : 데이터프레임\n",
    "## method : 사용할 스케일러 약자 mm >> MinMax , std >> Standard\n",
    "# output\n",
    "## scaled_data : numeric 칼럼을 스케일링 한 데이터 프레임\n",
    "def Scaler(data, method = 'mm'):\n",
    "    numeric = []\n",
    "    non_numeric = []\n",
    "    for col in data.columns:\n",
    "        if 'diff' in col:\n",
    "            numeric.append(col)\n",
    "        else:\n",
    "            non_numeric.append(col)\n",
    "    \n",
    "    # method 입력값에 따라 스케일러 종류가 달라짐\n",
    "    method_dict1 = {'mm': MinMaxScaler(),\n",
    "                    'std': StandardScaler()}\n",
    "    scaler = method_dict1[method]\n",
    "\n",
    "    #카테고리데이터는 따로 받아두고\n",
    "    non_scaled_data = np.array(data[non_numeric])\n",
    "\n",
    "    # numeric 칼럼은 스케일링후\n",
    "    scaled_data = scaler.fit_transform(data[numeric])\n",
    "\n",
    "    # 두 어레이를 합친후 데이터프레임으로\n",
    "    scaled_data = pd.DataFrame(np.c_[scaled_data,non_scaled_data])\n",
    "    # 칼럼명을 설정\n",
    "    scaled_data.columns = numeric + non_numeric\n",
    "\n",
    "    return scaled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue_diff</th>\n",
       "      <th>noi_diff</th>\n",
       "      <th>salescost_diff</th>\n",
       "      <th>sga_diff</th>\n",
       "      <th>noe_diff</th>\n",
       "      <th>ctax_diff</th>\n",
       "      <th>liquidLiabilities_diff</th>\n",
       "      <th>NCLiabilities_diff</th>\n",
       "      <th>liquidAsset_diff</th>\n",
       "      <th>nonCAsset_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>sido_8.0</th>\n",
       "      <th>sido_9.0</th>\n",
       "      <th>instkind_0.0</th>\n",
       "      <th>instkind_1.0</th>\n",
       "      <th>instkind_2.0</th>\n",
       "      <th>instkind_3.0</th>\n",
       "      <th>instkind_4.0</th>\n",
       "      <th>instkind_5.0</th>\n",
       "      <th>instkind_6.0</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.513842</td>\n",
       "      <td>0.153100</td>\n",
       "      <td>0.097874</td>\n",
       "      <td>0.453857</td>\n",
       "      <td>0.561128</td>\n",
       "      <td>0.482750</td>\n",
       "      <td>0.659936</td>\n",
       "      <td>0.575906</td>\n",
       "      <td>0.517749</td>\n",
       "      <td>0.180349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.557410</td>\n",
       "      <td>0.164839</td>\n",
       "      <td>0.112504</td>\n",
       "      <td>0.505276</td>\n",
       "      <td>0.552725</td>\n",
       "      <td>0.487610</td>\n",
       "      <td>0.678201</td>\n",
       "      <td>0.602277</td>\n",
       "      <td>0.534698</td>\n",
       "      <td>0.237511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.527972</td>\n",
       "      <td>0.153158</td>\n",
       "      <td>0.136881</td>\n",
       "      <td>0.461702</td>\n",
       "      <td>0.562192</td>\n",
       "      <td>0.475365</td>\n",
       "      <td>0.662398</td>\n",
       "      <td>0.576625</td>\n",
       "      <td>0.522332</td>\n",
       "      <td>0.183836</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.588468</td>\n",
       "      <td>0.155927</td>\n",
       "      <td>0.097874</td>\n",
       "      <td>0.538284</td>\n",
       "      <td>0.555417</td>\n",
       "      <td>0.449400</td>\n",
       "      <td>0.897430</td>\n",
       "      <td>0.492896</td>\n",
       "      <td>0.606094</td>\n",
       "      <td>0.262512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.527402</td>\n",
       "      <td>0.107350</td>\n",
       "      <td>0.097874</td>\n",
       "      <td>0.462900</td>\n",
       "      <td>0.554776</td>\n",
       "      <td>0.475365</td>\n",
       "      <td>0.635272</td>\n",
       "      <td>0.571743</td>\n",
       "      <td>0.580328</td>\n",
       "      <td>0.116270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.521998</td>\n",
       "      <td>0.148601</td>\n",
       "      <td>0.098598</td>\n",
       "      <td>0.442949</td>\n",
       "      <td>0.600688</td>\n",
       "      <td>0.445667</td>\n",
       "      <td>0.636680</td>\n",
       "      <td>0.581753</td>\n",
       "      <td>0.519967</td>\n",
       "      <td>0.173410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.436399</td>\n",
       "      <td>0.130636</td>\n",
       "      <td>0.602781</td>\n",
       "      <td>0.473635</td>\n",
       "      <td>0.519368</td>\n",
       "      <td>0.491858</td>\n",
       "      <td>0.667656</td>\n",
       "      <td>0.571213</td>\n",
       "      <td>0.524670</td>\n",
       "      <td>0.202010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.654915</td>\n",
       "      <td>0.148226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450943</td>\n",
       "      <td>0.562544</td>\n",
       "      <td>0.491858</td>\n",
       "      <td>0.657796</td>\n",
       "      <td>0.576625</td>\n",
       "      <td>0.497876</td>\n",
       "      <td>0.181448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.489098</td>\n",
       "      <td>0.163825</td>\n",
       "      <td>0.081376</td>\n",
       "      <td>0.434111</td>\n",
       "      <td>0.485648</td>\n",
       "      <td>0.479083</td>\n",
       "      <td>0.684315</td>\n",
       "      <td>0.576735</td>\n",
       "      <td>0.459175</td>\n",
       "      <td>0.180880</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.512830</td>\n",
       "      <td>0.152959</td>\n",
       "      <td>0.096213</td>\n",
       "      <td>0.454942</td>\n",
       "      <td>0.560690</td>\n",
       "      <td>0.495755</td>\n",
       "      <td>0.661796</td>\n",
       "      <td>0.576691</td>\n",
       "      <td>0.516879</td>\n",
       "      <td>0.177907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     revenue_diff  noi_diff  salescost_diff  sga_diff  noe_diff  ctax_diff  \\\n",
       "0        0.513842  0.153100        0.097874  0.453857  0.561128   0.482750   \n",
       "1        0.557410  0.164839        0.112504  0.505276  0.552725   0.487610   \n",
       "2        0.527972  0.153158        0.136881  0.461702  0.562192   0.475365   \n",
       "3        0.588468  0.155927        0.097874  0.538284  0.555417   0.449400   \n",
       "4        0.527402  0.107350        0.097874  0.462900  0.554776   0.475365   \n",
       "..            ...       ...             ...       ...       ...        ...   \n",
       "295      0.521998  0.148601        0.098598  0.442949  0.600688   0.445667   \n",
       "296      0.436399  0.130636        0.602781  0.473635  0.519368   0.491858   \n",
       "297      0.654915  0.148226        0.000000  0.450943  0.562544   0.491858   \n",
       "298      0.489098  0.163825        0.081376  0.434111  0.485648   0.479083   \n",
       "299      0.512830  0.152959        0.096213  0.454942  0.560690   0.495755   \n",
       "\n",
       "     liquidLiabilities_diff  NCLiabilities_diff  liquidAsset_diff  \\\n",
       "0                  0.659936            0.575906          0.517749   \n",
       "1                  0.678201            0.602277          0.534698   \n",
       "2                  0.662398            0.576625          0.522332   \n",
       "3                  0.897430            0.492896          0.606094   \n",
       "4                  0.635272            0.571743          0.580328   \n",
       "..                      ...                 ...               ...   \n",
       "295                0.636680            0.581753          0.519967   \n",
       "296                0.667656            0.571213          0.524670   \n",
       "297                0.657796            0.576625          0.497876   \n",
       "298                0.684315            0.576735          0.459175   \n",
       "299                0.661796            0.576691          0.516879   \n",
       "\n",
       "     nonCAsset_diff  ...  sido_8.0  sido_9.0  instkind_0.0  instkind_1.0  \\\n",
       "0          0.180349  ...       0.0       0.0           0.0           0.0   \n",
       "1          0.237511  ...       0.0       1.0           0.0           0.0   \n",
       "2          0.183836  ...       1.0       0.0           0.0           0.0   \n",
       "3          0.262512  ...       0.0       0.0           0.0           0.0   \n",
       "4          0.116270  ...       0.0       1.0           0.0           0.0   \n",
       "..              ...  ...       ...       ...           ...           ...   \n",
       "295        0.173410  ...       0.0       0.0           0.0           0.0   \n",
       "296        0.202010  ...       0.0       0.0           0.0           0.0   \n",
       "297        0.181448  ...       0.0       0.0           0.0           0.0   \n",
       "298        0.180880  ...       1.0       0.0           0.0           0.0   \n",
       "299        0.177907  ...       0.0       0.0           0.0           0.0   \n",
       "\n",
       "     instkind_2.0  instkind_3.0  instkind_4.0  instkind_5.0  instkind_6.0   OC  \n",
       "0             0.0           0.0           1.0           0.0           0.0  1.0  \n",
       "1             1.0           0.0           0.0           0.0           0.0  1.0  \n",
       "2             0.0           0.0           1.0           0.0           0.0  1.0  \n",
       "3             1.0           0.0           0.0           0.0           0.0  1.0  \n",
       "4             1.0           0.0           0.0           0.0           0.0  1.0  \n",
       "..            ...           ...           ...           ...           ...  ...  \n",
       "295           0.0           0.0           1.0           0.0           0.0  1.0  \n",
       "296           0.0           1.0           0.0           0.0           0.0  0.0  \n",
       "297           0.0           1.0           0.0           0.0           0.0  0.0  \n",
       "298           0.0           0.0           1.0           0.0           0.0  0.0  \n",
       "299           0.0           0.0           0.0           0.0           1.0  1.0  \n",
       "\n",
       "[300 rows x 34 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Scaler(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "칼럼간의 상관 분석<br>\n",
    "구한 데이터의 상관관계 분석을 하고 자기 자신과의 계수를 제외한 계수중 0.5 이상인 칼럼조합을 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation_analysis(data) -> (high_corr, new_list) <corr_map,high_corr_list>:\n",
    "# input\n",
    "## data : DataFrame\n",
    "# output\n",
    "## high_corr : 상관계수 매트릭스\n",
    "## new_list : 0.5 이상의 높은 상관관계를 가지는 칼럼 조합\n",
    "def correlation_analysis(data):\n",
    "\n",
    "    corr = data.corr()\n",
    "    high_corr = corr[np.abs(corr) > 0.5 ].style.background_gradient(cmap='coolwarm')\n",
    "\n",
    "    corelation_list = []\n",
    "    for i in corr.index:\n",
    "        for j in corr.columns:\n",
    "            if np.abs(corr.loc[i,j]) > 0.5 and i!=j :\n",
    "                print(i,j)\n",
    "                corelation_list.append((i,j))\n",
    "\n",
    "    new_list = []\n",
    "    for comb in corelation_list:\n",
    "        comb = list(comb)\n",
    "        comb = sorted(comb)\n",
    "        if comb in new_list:\n",
    "            pass\n",
    "        else:\n",
    "            new_list.append(comb)\n",
    "    new_list\n",
    "    \n",
    "    return high_corr, new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revenue_diff sga_diff\n",
      "noi_diff noe_diff\n",
      "sga_diff revenue_diff\n",
      "noe_diff noi_diff\n",
      "instkind_3.0 instkind_4.0\n",
      "instkind_4.0 instkind_3.0\n"
     ]
    }
   ],
   "source": [
    "corr_map, corr_col_list = correlation_analysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f7d14_row0_col0, #T_f7d14_row1_col1, #T_f7d14_row3_col3, #T_f7d14_row4_col4, #T_f7d14_row29_col29, #T_f7d14_row30_col30 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f7d14_row0_col1, #T_f7d14_row0_col4, #T_f7d14_row0_col29, #T_f7d14_row0_col30, #T_f7d14_row1_col0, #T_f7d14_row1_col3, #T_f7d14_row1_col29, #T_f7d14_row1_col30, #T_f7d14_row2_col0, #T_f7d14_row2_col1, #T_f7d14_row2_col3, #T_f7d14_row2_col4, #T_f7d14_row2_col29, #T_f7d14_row2_col30, #T_f7d14_row3_col1, #T_f7d14_row3_col4, #T_f7d14_row3_col29, #T_f7d14_row3_col30, #T_f7d14_row4_col0, #T_f7d14_row4_col3, #T_f7d14_row4_col29, #T_f7d14_row4_col30, #T_f7d14_row5_col0, #T_f7d14_row5_col1, #T_f7d14_row5_col3, #T_f7d14_row5_col4, #T_f7d14_row5_col29, #T_f7d14_row5_col30, #T_f7d14_row6_col0, #T_f7d14_row6_col1, #T_f7d14_row6_col3, #T_f7d14_row6_col4, #T_f7d14_row6_col29, #T_f7d14_row6_col30, #T_f7d14_row7_col0, #T_f7d14_row7_col1, #T_f7d14_row7_col3, #T_f7d14_row7_col4, #T_f7d14_row7_col29, #T_f7d14_row7_col30, #T_f7d14_row8_col0, #T_f7d14_row8_col1, #T_f7d14_row8_col3, #T_f7d14_row8_col4, #T_f7d14_row8_col29, #T_f7d14_row8_col30, #T_f7d14_row9_col0, #T_f7d14_row9_col1, #T_f7d14_row9_col3, #T_f7d14_row9_col4, #T_f7d14_row9_col29, #T_f7d14_row9_col30, #T_f7d14_row10_col0, #T_f7d14_row10_col1, #T_f7d14_row10_col3, #T_f7d14_row10_col4, #T_f7d14_row10_col29, #T_f7d14_row10_col30, #T_f7d14_row11_col0, #T_f7d14_row11_col1, #T_f7d14_row11_col3, #T_f7d14_row11_col4, #T_f7d14_row11_col29, #T_f7d14_row11_col30, #T_f7d14_row12_col0, #T_f7d14_row12_col1, #T_f7d14_row12_col3, #T_f7d14_row12_col4, #T_f7d14_row12_col29, #T_f7d14_row12_col30, #T_f7d14_row13_col0, #T_f7d14_row13_col1, #T_f7d14_row13_col3, #T_f7d14_row13_col4, #T_f7d14_row13_col29, #T_f7d14_row13_col30, #T_f7d14_row14_col0, #T_f7d14_row14_col1, #T_f7d14_row14_col3, #T_f7d14_row14_col4, #T_f7d14_row14_col29, #T_f7d14_row14_col30, #T_f7d14_row15_col0, #T_f7d14_row15_col1, #T_f7d14_row15_col3, #T_f7d14_row15_col4, #T_f7d14_row15_col29, #T_f7d14_row15_col30, #T_f7d14_row16_col0, #T_f7d14_row16_col1, #T_f7d14_row16_col3, #T_f7d14_row16_col4, #T_f7d14_row16_col29, #T_f7d14_row16_col30, #T_f7d14_row17_col0, #T_f7d14_row17_col1, #T_f7d14_row17_col3, #T_f7d14_row17_col4, #T_f7d14_row17_col29, #T_f7d14_row17_col30, #T_f7d14_row18_col0, #T_f7d14_row18_col1, #T_f7d14_row18_col3, #T_f7d14_row18_col4, #T_f7d14_row18_col29, #T_f7d14_row18_col30, #T_f7d14_row19_col0, #T_f7d14_row19_col1, #T_f7d14_row19_col3, #T_f7d14_row19_col4, #T_f7d14_row19_col29, #T_f7d14_row19_col30, #T_f7d14_row20_col0, #T_f7d14_row20_col1, #T_f7d14_row20_col3, #T_f7d14_row20_col4, #T_f7d14_row20_col29, #T_f7d14_row20_col30, #T_f7d14_row21_col0, #T_f7d14_row21_col1, #T_f7d14_row21_col3, #T_f7d14_row21_col4, #T_f7d14_row21_col29, #T_f7d14_row21_col30, #T_f7d14_row22_col0, #T_f7d14_row22_col1, #T_f7d14_row22_col3, #T_f7d14_row22_col4, #T_f7d14_row22_col29, #T_f7d14_row22_col30, #T_f7d14_row23_col0, #T_f7d14_row23_col1, #T_f7d14_row23_col3, #T_f7d14_row23_col4, #T_f7d14_row23_col29, #T_f7d14_row23_col30, #T_f7d14_row24_col0, #T_f7d14_row24_col1, #T_f7d14_row24_col3, #T_f7d14_row24_col4, #T_f7d14_row24_col29, #T_f7d14_row24_col30, #T_f7d14_row25_col0, #T_f7d14_row25_col1, #T_f7d14_row25_col3, #T_f7d14_row25_col4, #T_f7d14_row25_col29, #T_f7d14_row25_col30, #T_f7d14_row26_col0, #T_f7d14_row26_col1, #T_f7d14_row26_col3, #T_f7d14_row26_col4, #T_f7d14_row26_col29, #T_f7d14_row26_col30, #T_f7d14_row27_col0, #T_f7d14_row27_col1, #T_f7d14_row27_col3, #T_f7d14_row27_col4, #T_f7d14_row27_col29, #T_f7d14_row27_col30, #T_f7d14_row28_col0, #T_f7d14_row28_col1, #T_f7d14_row28_col3, #T_f7d14_row28_col4, #T_f7d14_row28_col29, #T_f7d14_row28_col30, #T_f7d14_row29_col0, #T_f7d14_row29_col1, #T_f7d14_row29_col3, #T_f7d14_row29_col4, #T_f7d14_row30_col0, #T_f7d14_row30_col1, #T_f7d14_row30_col3, #T_f7d14_row30_col4, #T_f7d14_row31_col0, #T_f7d14_row31_col1, #T_f7d14_row31_col3, #T_f7d14_row31_col4, #T_f7d14_row31_col29, #T_f7d14_row31_col30, #T_f7d14_row32_col0, #T_f7d14_row32_col1, #T_f7d14_row32_col3, #T_f7d14_row32_col4, #T_f7d14_row32_col29, #T_f7d14_row32_col30, #T_f7d14_row33_col0, #T_f7d14_row33_col1, #T_f7d14_row33_col3, #T_f7d14_row33_col4, #T_f7d14_row33_col29, #T_f7d14_row33_col30 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f7d14_row0_col2, #T_f7d14_row0_col3, #T_f7d14_row0_col5, #T_f7d14_row0_col6, #T_f7d14_row0_col7, #T_f7d14_row0_col8, #T_f7d14_row0_col9, #T_f7d14_row0_col10, #T_f7d14_row0_col11, #T_f7d14_row0_col12, #T_f7d14_row0_col13, #T_f7d14_row0_col14, #T_f7d14_row0_col15, #T_f7d14_row0_col16, #T_f7d14_row0_col17, #T_f7d14_row0_col18, #T_f7d14_row0_col19, #T_f7d14_row0_col20, #T_f7d14_row0_col21, #T_f7d14_row0_col22, #T_f7d14_row0_col23, #T_f7d14_row0_col24, #T_f7d14_row0_col25, #T_f7d14_row0_col26, #T_f7d14_row0_col27, #T_f7d14_row0_col28, #T_f7d14_row0_col31, #T_f7d14_row0_col32, #T_f7d14_row0_col33, #T_f7d14_row1_col2, #T_f7d14_row1_col4, #T_f7d14_row1_col5, #T_f7d14_row1_col6, #T_f7d14_row1_col7, #T_f7d14_row1_col8, #T_f7d14_row1_col9, #T_f7d14_row1_col10, #T_f7d14_row1_col11, #T_f7d14_row1_col12, #T_f7d14_row1_col13, #T_f7d14_row1_col14, #T_f7d14_row1_col15, #T_f7d14_row1_col16, #T_f7d14_row1_col17, #T_f7d14_row1_col18, #T_f7d14_row1_col19, #T_f7d14_row1_col20, #T_f7d14_row1_col21, #T_f7d14_row1_col22, #T_f7d14_row1_col23, #T_f7d14_row1_col24, #T_f7d14_row1_col25, #T_f7d14_row1_col26, #T_f7d14_row1_col27, #T_f7d14_row1_col28, #T_f7d14_row1_col31, #T_f7d14_row1_col32, #T_f7d14_row1_col33, #T_f7d14_row2_col2, #T_f7d14_row2_col5, #T_f7d14_row2_col6, #T_f7d14_row2_col7, #T_f7d14_row2_col8, #T_f7d14_row2_col9, #T_f7d14_row2_col10, #T_f7d14_row2_col11, #T_f7d14_row2_col12, #T_f7d14_row2_col13, #T_f7d14_row2_col14, #T_f7d14_row2_col15, #T_f7d14_row2_col16, #T_f7d14_row2_col17, #T_f7d14_row2_col18, #T_f7d14_row2_col19, #T_f7d14_row2_col20, #T_f7d14_row2_col21, #T_f7d14_row2_col22, #T_f7d14_row2_col23, #T_f7d14_row2_col24, #T_f7d14_row2_col25, #T_f7d14_row2_col26, #T_f7d14_row2_col27, #T_f7d14_row2_col28, #T_f7d14_row2_col31, #T_f7d14_row2_col32, #T_f7d14_row2_col33, #T_f7d14_row3_col0, #T_f7d14_row3_col2, #T_f7d14_row3_col5, #T_f7d14_row3_col6, #T_f7d14_row3_col7, #T_f7d14_row3_col8, #T_f7d14_row3_col9, #T_f7d14_row3_col10, #T_f7d14_row3_col11, #T_f7d14_row3_col12, #T_f7d14_row3_col13, #T_f7d14_row3_col14, #T_f7d14_row3_col15, #T_f7d14_row3_col16, #T_f7d14_row3_col17, #T_f7d14_row3_col18, #T_f7d14_row3_col19, #T_f7d14_row3_col20, #T_f7d14_row3_col21, #T_f7d14_row3_col22, #T_f7d14_row3_col23, #T_f7d14_row3_col24, #T_f7d14_row3_col25, #T_f7d14_row3_col26, #T_f7d14_row3_col27, #T_f7d14_row3_col28, #T_f7d14_row3_col31, #T_f7d14_row3_col32, #T_f7d14_row3_col33, #T_f7d14_row4_col1, #T_f7d14_row4_col2, #T_f7d14_row4_col5, #T_f7d14_row4_col6, #T_f7d14_row4_col7, #T_f7d14_row4_col8, #T_f7d14_row4_col9, #T_f7d14_row4_col10, #T_f7d14_row4_col11, #T_f7d14_row4_col12, #T_f7d14_row4_col13, #T_f7d14_row4_col14, #T_f7d14_row4_col15, #T_f7d14_row4_col16, #T_f7d14_row4_col17, #T_f7d14_row4_col18, #T_f7d14_row4_col19, #T_f7d14_row4_col20, #T_f7d14_row4_col21, #T_f7d14_row4_col22, #T_f7d14_row4_col23, #T_f7d14_row4_col24, #T_f7d14_row4_col25, #T_f7d14_row4_col26, #T_f7d14_row4_col27, #T_f7d14_row4_col28, #T_f7d14_row4_col31, #T_f7d14_row4_col32, #T_f7d14_row4_col33, #T_f7d14_row5_col2, #T_f7d14_row5_col5, #T_f7d14_row5_col6, #T_f7d14_row5_col7, #T_f7d14_row5_col8, #T_f7d14_row5_col9, #T_f7d14_row5_col10, #T_f7d14_row5_col11, #T_f7d14_row5_col12, #T_f7d14_row5_col13, #T_f7d14_row5_col14, #T_f7d14_row5_col15, #T_f7d14_row5_col16, #T_f7d14_row5_col17, #T_f7d14_row5_col18, #T_f7d14_row5_col19, #T_f7d14_row5_col20, #T_f7d14_row5_col21, #T_f7d14_row5_col22, #T_f7d14_row5_col23, #T_f7d14_row5_col24, #T_f7d14_row5_col25, #T_f7d14_row5_col26, #T_f7d14_row5_col27, #T_f7d14_row5_col28, #T_f7d14_row5_col31, #T_f7d14_row5_col32, #T_f7d14_row5_col33, #T_f7d14_row6_col2, #T_f7d14_row6_col5, #T_f7d14_row6_col6, #T_f7d14_row6_col7, #T_f7d14_row6_col8, #T_f7d14_row6_col9, #T_f7d14_row6_col10, #T_f7d14_row6_col11, #T_f7d14_row6_col12, #T_f7d14_row6_col13, #T_f7d14_row6_col14, #T_f7d14_row6_col15, #T_f7d14_row6_col16, #T_f7d14_row6_col17, #T_f7d14_row6_col18, #T_f7d14_row6_col19, #T_f7d14_row6_col20, #T_f7d14_row6_col21, #T_f7d14_row6_col22, #T_f7d14_row6_col23, #T_f7d14_row6_col24, #T_f7d14_row6_col25, #T_f7d14_row6_col26, #T_f7d14_row6_col27, #T_f7d14_row6_col28, #T_f7d14_row6_col31, #T_f7d14_row6_col32, #T_f7d14_row6_col33, #T_f7d14_row7_col2, #T_f7d14_row7_col5, #T_f7d14_row7_col6, #T_f7d14_row7_col7, #T_f7d14_row7_col8, #T_f7d14_row7_col9, #T_f7d14_row7_col10, #T_f7d14_row7_col11, #T_f7d14_row7_col12, #T_f7d14_row7_col13, #T_f7d14_row7_col14, #T_f7d14_row7_col15, #T_f7d14_row7_col16, #T_f7d14_row7_col17, #T_f7d14_row7_col18, #T_f7d14_row7_col19, #T_f7d14_row7_col20, #T_f7d14_row7_col21, #T_f7d14_row7_col22, #T_f7d14_row7_col23, #T_f7d14_row7_col24, #T_f7d14_row7_col25, #T_f7d14_row7_col26, #T_f7d14_row7_col27, #T_f7d14_row7_col28, #T_f7d14_row7_col31, #T_f7d14_row7_col32, #T_f7d14_row7_col33, #T_f7d14_row8_col2, #T_f7d14_row8_col5, #T_f7d14_row8_col6, #T_f7d14_row8_col7, #T_f7d14_row8_col8, #T_f7d14_row8_col9, #T_f7d14_row8_col10, #T_f7d14_row8_col11, #T_f7d14_row8_col12, #T_f7d14_row8_col13, #T_f7d14_row8_col14, #T_f7d14_row8_col15, #T_f7d14_row8_col16, #T_f7d14_row8_col17, #T_f7d14_row8_col18, #T_f7d14_row8_col19, #T_f7d14_row8_col20, #T_f7d14_row8_col21, #T_f7d14_row8_col22, #T_f7d14_row8_col23, #T_f7d14_row8_col24, #T_f7d14_row8_col25, #T_f7d14_row8_col26, #T_f7d14_row8_col27, #T_f7d14_row8_col28, #T_f7d14_row8_col31, #T_f7d14_row8_col32, #T_f7d14_row8_col33, #T_f7d14_row9_col2, #T_f7d14_row9_col5, #T_f7d14_row9_col6, #T_f7d14_row9_col7, #T_f7d14_row9_col8, #T_f7d14_row9_col9, #T_f7d14_row9_col10, #T_f7d14_row9_col11, #T_f7d14_row9_col12, #T_f7d14_row9_col13, #T_f7d14_row9_col14, #T_f7d14_row9_col15, #T_f7d14_row9_col16, #T_f7d14_row9_col17, #T_f7d14_row9_col18, #T_f7d14_row9_col19, #T_f7d14_row9_col20, #T_f7d14_row9_col21, #T_f7d14_row9_col22, #T_f7d14_row9_col23, #T_f7d14_row9_col24, #T_f7d14_row9_col25, #T_f7d14_row9_col26, #T_f7d14_row9_col27, #T_f7d14_row9_col28, #T_f7d14_row9_col31, #T_f7d14_row9_col32, #T_f7d14_row9_col33, #T_f7d14_row10_col2, #T_f7d14_row10_col5, #T_f7d14_row10_col6, #T_f7d14_row10_col7, #T_f7d14_row10_col8, #T_f7d14_row10_col9, #T_f7d14_row10_col10, #T_f7d14_row10_col11, #T_f7d14_row10_col12, #T_f7d14_row10_col13, #T_f7d14_row10_col14, #T_f7d14_row10_col15, #T_f7d14_row10_col16, #T_f7d14_row10_col17, #T_f7d14_row10_col18, #T_f7d14_row10_col19, #T_f7d14_row10_col20, #T_f7d14_row10_col21, #T_f7d14_row10_col22, #T_f7d14_row10_col23, #T_f7d14_row10_col24, #T_f7d14_row10_col25, #T_f7d14_row10_col26, #T_f7d14_row10_col27, #T_f7d14_row10_col28, #T_f7d14_row10_col31, #T_f7d14_row10_col32, #T_f7d14_row10_col33, #T_f7d14_row11_col2, #T_f7d14_row11_col5, #T_f7d14_row11_col6, #T_f7d14_row11_col7, #T_f7d14_row11_col8, #T_f7d14_row11_col9, #T_f7d14_row11_col10, #T_f7d14_row11_col11, #T_f7d14_row11_col12, #T_f7d14_row11_col13, #T_f7d14_row11_col14, #T_f7d14_row11_col15, #T_f7d14_row11_col16, #T_f7d14_row11_col17, #T_f7d14_row11_col18, #T_f7d14_row11_col19, #T_f7d14_row11_col20, #T_f7d14_row11_col21, #T_f7d14_row11_col22, #T_f7d14_row11_col23, #T_f7d14_row11_col24, #T_f7d14_row11_col25, #T_f7d14_row11_col26, #T_f7d14_row11_col27, #T_f7d14_row11_col28, #T_f7d14_row11_col31, #T_f7d14_row11_col32, #T_f7d14_row11_col33, #T_f7d14_row12_col2, #T_f7d14_row12_col5, #T_f7d14_row12_col6, #T_f7d14_row12_col7, #T_f7d14_row12_col8, #T_f7d14_row12_col9, #T_f7d14_row12_col10, #T_f7d14_row12_col11, #T_f7d14_row12_col12, #T_f7d14_row12_col13, #T_f7d14_row12_col14, #T_f7d14_row12_col15, #T_f7d14_row12_col16, #T_f7d14_row12_col17, #T_f7d14_row12_col18, #T_f7d14_row12_col19, #T_f7d14_row12_col20, #T_f7d14_row12_col21, #T_f7d14_row12_col22, #T_f7d14_row12_col23, #T_f7d14_row12_col24, #T_f7d14_row12_col25, #T_f7d14_row12_col26, #T_f7d14_row12_col27, #T_f7d14_row12_col28, #T_f7d14_row12_col31, #T_f7d14_row12_col32, #T_f7d14_row12_col33, #T_f7d14_row13_col2, #T_f7d14_row13_col5, #T_f7d14_row13_col6, #T_f7d14_row13_col7, #T_f7d14_row13_col8, #T_f7d14_row13_col9, #T_f7d14_row13_col10, #T_f7d14_row13_col11, #T_f7d14_row13_col12, #T_f7d14_row13_col13, #T_f7d14_row13_col14, #T_f7d14_row13_col15, #T_f7d14_row13_col16, #T_f7d14_row13_col17, #T_f7d14_row13_col18, #T_f7d14_row13_col19, #T_f7d14_row13_col20, #T_f7d14_row13_col21, #T_f7d14_row13_col22, #T_f7d14_row13_col23, #T_f7d14_row13_col24, #T_f7d14_row13_col25, #T_f7d14_row13_col26, #T_f7d14_row13_col27, #T_f7d14_row13_col28, #T_f7d14_row13_col31, #T_f7d14_row13_col32, #T_f7d14_row13_col33, #T_f7d14_row14_col2, #T_f7d14_row14_col5, #T_f7d14_row14_col6, #T_f7d14_row14_col7, #T_f7d14_row14_col8, #T_f7d14_row14_col9, #T_f7d14_row14_col10, #T_f7d14_row14_col11, #T_f7d14_row14_col12, #T_f7d14_row14_col13, #T_f7d14_row14_col14, #T_f7d14_row14_col15, #T_f7d14_row14_col16, #T_f7d14_row14_col17, #T_f7d14_row14_col18, #T_f7d14_row14_col19, #T_f7d14_row14_col20, #T_f7d14_row14_col21, #T_f7d14_row14_col22, #T_f7d14_row14_col23, #T_f7d14_row14_col24, #T_f7d14_row14_col25, #T_f7d14_row14_col26, #T_f7d14_row14_col27, #T_f7d14_row14_col28, #T_f7d14_row14_col31, #T_f7d14_row14_col32, #T_f7d14_row14_col33, #T_f7d14_row15_col2, #T_f7d14_row15_col5, #T_f7d14_row15_col6, #T_f7d14_row15_col7, #T_f7d14_row15_col8, #T_f7d14_row15_col9, #T_f7d14_row15_col10, #T_f7d14_row15_col11, #T_f7d14_row15_col12, #T_f7d14_row15_col13, #T_f7d14_row15_col14, #T_f7d14_row15_col15, #T_f7d14_row15_col16, #T_f7d14_row15_col17, #T_f7d14_row15_col18, #T_f7d14_row15_col19, #T_f7d14_row15_col20, #T_f7d14_row15_col21, #T_f7d14_row15_col22, #T_f7d14_row15_col23, #T_f7d14_row15_col24, #T_f7d14_row15_col25, #T_f7d14_row15_col26, #T_f7d14_row15_col27, #T_f7d14_row15_col28, #T_f7d14_row15_col31, #T_f7d14_row15_col32, #T_f7d14_row15_col33, #T_f7d14_row16_col2, #T_f7d14_row16_col5, #T_f7d14_row16_col6, #T_f7d14_row16_col7, #T_f7d14_row16_col8, #T_f7d14_row16_col9, #T_f7d14_row16_col10, #T_f7d14_row16_col11, #T_f7d14_row16_col12, #T_f7d14_row16_col13, #T_f7d14_row16_col14, #T_f7d14_row16_col15, #T_f7d14_row16_col16, #T_f7d14_row16_col17, #T_f7d14_row16_col18, #T_f7d14_row16_col19, #T_f7d14_row16_col20, #T_f7d14_row16_col21, #T_f7d14_row16_col22, #T_f7d14_row16_col23, #T_f7d14_row16_col24, #T_f7d14_row16_col25, #T_f7d14_row16_col26, #T_f7d14_row16_col27, #T_f7d14_row16_col28, #T_f7d14_row16_col31, #T_f7d14_row16_col32, #T_f7d14_row16_col33, #T_f7d14_row17_col2, #T_f7d14_row17_col5, #T_f7d14_row17_col6, #T_f7d14_row17_col7, #T_f7d14_row17_col8, #T_f7d14_row17_col9, #T_f7d14_row17_col10, #T_f7d14_row17_col11, #T_f7d14_row17_col12, #T_f7d14_row17_col13, #T_f7d14_row17_col14, #T_f7d14_row17_col15, #T_f7d14_row17_col16, #T_f7d14_row17_col17, #T_f7d14_row17_col18, #T_f7d14_row17_col19, #T_f7d14_row17_col20, #T_f7d14_row17_col21, #T_f7d14_row17_col22, #T_f7d14_row17_col23, #T_f7d14_row17_col24, #T_f7d14_row17_col25, #T_f7d14_row17_col26, #T_f7d14_row17_col27, #T_f7d14_row17_col28, #T_f7d14_row17_col31, #T_f7d14_row17_col32, #T_f7d14_row17_col33, #T_f7d14_row18_col2, #T_f7d14_row18_col5, #T_f7d14_row18_col6, #T_f7d14_row18_col7, #T_f7d14_row18_col8, #T_f7d14_row18_col9, #T_f7d14_row18_col10, #T_f7d14_row18_col11, #T_f7d14_row18_col12, #T_f7d14_row18_col13, #T_f7d14_row18_col14, #T_f7d14_row18_col15, #T_f7d14_row18_col16, #T_f7d14_row18_col17, #T_f7d14_row18_col18, #T_f7d14_row18_col19, #T_f7d14_row18_col20, #T_f7d14_row18_col21, #T_f7d14_row18_col22, #T_f7d14_row18_col23, #T_f7d14_row18_col24, #T_f7d14_row18_col25, #T_f7d14_row18_col26, #T_f7d14_row18_col27, #T_f7d14_row18_col28, #T_f7d14_row18_col31, #T_f7d14_row18_col32, #T_f7d14_row18_col33, #T_f7d14_row19_col2, #T_f7d14_row19_col5, #T_f7d14_row19_col6, #T_f7d14_row19_col7, #T_f7d14_row19_col8, #T_f7d14_row19_col9, #T_f7d14_row19_col10, #T_f7d14_row19_col11, #T_f7d14_row19_col12, #T_f7d14_row19_col13, #T_f7d14_row19_col14, #T_f7d14_row19_col15, #T_f7d14_row19_col16, #T_f7d14_row19_col17, #T_f7d14_row19_col18, #T_f7d14_row19_col19, #T_f7d14_row19_col20, #T_f7d14_row19_col21, #T_f7d14_row19_col22, #T_f7d14_row19_col23, #T_f7d14_row19_col24, #T_f7d14_row19_col25, #T_f7d14_row19_col26, #T_f7d14_row19_col27, #T_f7d14_row19_col28, #T_f7d14_row19_col31, #T_f7d14_row19_col32, #T_f7d14_row19_col33, #T_f7d14_row20_col2, #T_f7d14_row20_col5, #T_f7d14_row20_col6, #T_f7d14_row20_col7, #T_f7d14_row20_col8, #T_f7d14_row20_col9, #T_f7d14_row20_col10, #T_f7d14_row20_col11, #T_f7d14_row20_col12, #T_f7d14_row20_col13, #T_f7d14_row20_col14, #T_f7d14_row20_col15, #T_f7d14_row20_col16, #T_f7d14_row20_col17, #T_f7d14_row20_col18, #T_f7d14_row20_col19, #T_f7d14_row20_col20, #T_f7d14_row20_col21, #T_f7d14_row20_col22, #T_f7d14_row20_col23, #T_f7d14_row20_col24, #T_f7d14_row20_col25, #T_f7d14_row20_col26, #T_f7d14_row20_col27, #T_f7d14_row20_col28, #T_f7d14_row20_col31, #T_f7d14_row20_col32, #T_f7d14_row20_col33, #T_f7d14_row21_col2, #T_f7d14_row21_col5, #T_f7d14_row21_col6, #T_f7d14_row21_col7, #T_f7d14_row21_col8, #T_f7d14_row21_col9, #T_f7d14_row21_col10, #T_f7d14_row21_col11, #T_f7d14_row21_col12, #T_f7d14_row21_col13, #T_f7d14_row21_col14, #T_f7d14_row21_col15, #T_f7d14_row21_col16, #T_f7d14_row21_col17, #T_f7d14_row21_col18, #T_f7d14_row21_col19, #T_f7d14_row21_col20, #T_f7d14_row21_col21, #T_f7d14_row21_col22, #T_f7d14_row21_col23, #T_f7d14_row21_col24, #T_f7d14_row21_col25, #T_f7d14_row21_col26, #T_f7d14_row21_col27, #T_f7d14_row21_col28, #T_f7d14_row21_col31, #T_f7d14_row21_col32, #T_f7d14_row21_col33, #T_f7d14_row22_col2, #T_f7d14_row22_col5, #T_f7d14_row22_col6, #T_f7d14_row22_col7, #T_f7d14_row22_col8, #T_f7d14_row22_col9, #T_f7d14_row22_col10, #T_f7d14_row22_col11, #T_f7d14_row22_col12, #T_f7d14_row22_col13, #T_f7d14_row22_col14, #T_f7d14_row22_col15, #T_f7d14_row22_col16, #T_f7d14_row22_col17, #T_f7d14_row22_col18, #T_f7d14_row22_col19, #T_f7d14_row22_col20, #T_f7d14_row22_col21, #T_f7d14_row22_col22, #T_f7d14_row22_col23, #T_f7d14_row22_col24, #T_f7d14_row22_col25, #T_f7d14_row22_col26, #T_f7d14_row22_col27, #T_f7d14_row22_col28, #T_f7d14_row22_col31, #T_f7d14_row22_col32, #T_f7d14_row22_col33, #T_f7d14_row23_col2, #T_f7d14_row23_col5, #T_f7d14_row23_col6, #T_f7d14_row23_col7, #T_f7d14_row23_col8, #T_f7d14_row23_col9, #T_f7d14_row23_col10, #T_f7d14_row23_col11, #T_f7d14_row23_col12, #T_f7d14_row23_col13, #T_f7d14_row23_col14, #T_f7d14_row23_col15, #T_f7d14_row23_col16, #T_f7d14_row23_col17, #T_f7d14_row23_col18, #T_f7d14_row23_col19, #T_f7d14_row23_col20, #T_f7d14_row23_col21, #T_f7d14_row23_col22, #T_f7d14_row23_col23, #T_f7d14_row23_col24, #T_f7d14_row23_col25, #T_f7d14_row23_col26, #T_f7d14_row23_col27, #T_f7d14_row23_col28, #T_f7d14_row23_col31, #T_f7d14_row23_col32, #T_f7d14_row23_col33, #T_f7d14_row24_col2, #T_f7d14_row24_col5, #T_f7d14_row24_col6, #T_f7d14_row24_col7, #T_f7d14_row24_col8, #T_f7d14_row24_col9, #T_f7d14_row24_col10, #T_f7d14_row24_col11, #T_f7d14_row24_col12, #T_f7d14_row24_col13, #T_f7d14_row24_col14, #T_f7d14_row24_col15, #T_f7d14_row24_col16, #T_f7d14_row24_col17, #T_f7d14_row24_col18, #T_f7d14_row24_col19, #T_f7d14_row24_col20, #T_f7d14_row24_col21, #T_f7d14_row24_col22, #T_f7d14_row24_col23, #T_f7d14_row24_col24, #T_f7d14_row24_col25, #T_f7d14_row24_col26, #T_f7d14_row24_col27, #T_f7d14_row24_col28, #T_f7d14_row24_col31, #T_f7d14_row24_col32, #T_f7d14_row24_col33, #T_f7d14_row25_col2, #T_f7d14_row25_col5, #T_f7d14_row25_col6, #T_f7d14_row25_col7, #T_f7d14_row25_col8, #T_f7d14_row25_col9, #T_f7d14_row25_col10, #T_f7d14_row25_col11, #T_f7d14_row25_col12, #T_f7d14_row25_col13, #T_f7d14_row25_col14, #T_f7d14_row25_col15, #T_f7d14_row25_col16, #T_f7d14_row25_col17, #T_f7d14_row25_col18, #T_f7d14_row25_col19, #T_f7d14_row25_col20, #T_f7d14_row25_col21, #T_f7d14_row25_col22, #T_f7d14_row25_col23, #T_f7d14_row25_col24, #T_f7d14_row25_col25, #T_f7d14_row25_col26, #T_f7d14_row25_col27, #T_f7d14_row25_col28, #T_f7d14_row25_col31, #T_f7d14_row25_col32, #T_f7d14_row25_col33, #T_f7d14_row26_col2, #T_f7d14_row26_col5, #T_f7d14_row26_col6, #T_f7d14_row26_col7, #T_f7d14_row26_col8, #T_f7d14_row26_col9, #T_f7d14_row26_col10, #T_f7d14_row26_col11, #T_f7d14_row26_col12, #T_f7d14_row26_col13, #T_f7d14_row26_col14, #T_f7d14_row26_col15, #T_f7d14_row26_col16, #T_f7d14_row26_col17, #T_f7d14_row26_col18, #T_f7d14_row26_col19, #T_f7d14_row26_col20, #T_f7d14_row26_col21, #T_f7d14_row26_col22, #T_f7d14_row26_col23, #T_f7d14_row26_col24, #T_f7d14_row26_col25, #T_f7d14_row26_col26, #T_f7d14_row26_col27, #T_f7d14_row26_col28, #T_f7d14_row26_col31, #T_f7d14_row26_col32, #T_f7d14_row26_col33, #T_f7d14_row27_col2, #T_f7d14_row27_col5, #T_f7d14_row27_col6, #T_f7d14_row27_col7, #T_f7d14_row27_col8, #T_f7d14_row27_col9, #T_f7d14_row27_col10, #T_f7d14_row27_col11, #T_f7d14_row27_col12, #T_f7d14_row27_col13, #T_f7d14_row27_col14, #T_f7d14_row27_col15, #T_f7d14_row27_col16, #T_f7d14_row27_col17, #T_f7d14_row27_col18, #T_f7d14_row27_col19, #T_f7d14_row27_col20, #T_f7d14_row27_col21, #T_f7d14_row27_col22, #T_f7d14_row27_col23, #T_f7d14_row27_col24, #T_f7d14_row27_col25, #T_f7d14_row27_col26, #T_f7d14_row27_col27, #T_f7d14_row27_col28, #T_f7d14_row27_col31, #T_f7d14_row27_col32, #T_f7d14_row27_col33, #T_f7d14_row28_col2, #T_f7d14_row28_col5, #T_f7d14_row28_col6, #T_f7d14_row28_col7, #T_f7d14_row28_col8, #T_f7d14_row28_col9, #T_f7d14_row28_col10, #T_f7d14_row28_col11, #T_f7d14_row28_col12, #T_f7d14_row28_col13, #T_f7d14_row28_col14, #T_f7d14_row28_col15, #T_f7d14_row28_col16, #T_f7d14_row28_col17, #T_f7d14_row28_col18, #T_f7d14_row28_col19, #T_f7d14_row28_col20, #T_f7d14_row28_col21, #T_f7d14_row28_col22, #T_f7d14_row28_col23, #T_f7d14_row28_col24, #T_f7d14_row28_col25, #T_f7d14_row28_col26, #T_f7d14_row28_col27, #T_f7d14_row28_col28, #T_f7d14_row28_col31, #T_f7d14_row28_col32, #T_f7d14_row28_col33, #T_f7d14_row29_col2, #T_f7d14_row29_col5, #T_f7d14_row29_col6, #T_f7d14_row29_col7, #T_f7d14_row29_col8, #T_f7d14_row29_col9, #T_f7d14_row29_col10, #T_f7d14_row29_col11, #T_f7d14_row29_col12, #T_f7d14_row29_col13, #T_f7d14_row29_col14, #T_f7d14_row29_col15, #T_f7d14_row29_col16, #T_f7d14_row29_col17, #T_f7d14_row29_col18, #T_f7d14_row29_col19, #T_f7d14_row29_col20, #T_f7d14_row29_col21, #T_f7d14_row29_col22, #T_f7d14_row29_col23, #T_f7d14_row29_col24, #T_f7d14_row29_col25, #T_f7d14_row29_col26, #T_f7d14_row29_col27, #T_f7d14_row29_col28, #T_f7d14_row29_col30, #T_f7d14_row29_col31, #T_f7d14_row29_col32, #T_f7d14_row29_col33, #T_f7d14_row30_col2, #T_f7d14_row30_col5, #T_f7d14_row30_col6, #T_f7d14_row30_col7, #T_f7d14_row30_col8, #T_f7d14_row30_col9, #T_f7d14_row30_col10, #T_f7d14_row30_col11, #T_f7d14_row30_col12, #T_f7d14_row30_col13, #T_f7d14_row30_col14, #T_f7d14_row30_col15, #T_f7d14_row30_col16, #T_f7d14_row30_col17, #T_f7d14_row30_col18, #T_f7d14_row30_col19, #T_f7d14_row30_col20, #T_f7d14_row30_col21, #T_f7d14_row30_col22, #T_f7d14_row30_col23, #T_f7d14_row30_col24, #T_f7d14_row30_col25, #T_f7d14_row30_col26, #T_f7d14_row30_col27, #T_f7d14_row30_col28, #T_f7d14_row30_col29, #T_f7d14_row30_col31, #T_f7d14_row30_col32, #T_f7d14_row30_col33, #T_f7d14_row31_col2, #T_f7d14_row31_col5, #T_f7d14_row31_col6, #T_f7d14_row31_col7, #T_f7d14_row31_col8, #T_f7d14_row31_col9, #T_f7d14_row31_col10, #T_f7d14_row31_col11, #T_f7d14_row31_col12, #T_f7d14_row31_col13, #T_f7d14_row31_col14, #T_f7d14_row31_col15, #T_f7d14_row31_col16, #T_f7d14_row31_col17, #T_f7d14_row31_col18, #T_f7d14_row31_col19, #T_f7d14_row31_col20, #T_f7d14_row31_col21, #T_f7d14_row31_col22, #T_f7d14_row31_col23, #T_f7d14_row31_col24, #T_f7d14_row31_col25, #T_f7d14_row31_col26, #T_f7d14_row31_col27, #T_f7d14_row31_col28, #T_f7d14_row31_col31, #T_f7d14_row31_col32, #T_f7d14_row31_col33, #T_f7d14_row32_col2, #T_f7d14_row32_col5, #T_f7d14_row32_col6, #T_f7d14_row32_col7, #T_f7d14_row32_col8, #T_f7d14_row32_col9, #T_f7d14_row32_col10, #T_f7d14_row32_col11, #T_f7d14_row32_col12, #T_f7d14_row32_col13, #T_f7d14_row32_col14, #T_f7d14_row32_col15, #T_f7d14_row32_col16, #T_f7d14_row32_col17, #T_f7d14_row32_col18, #T_f7d14_row32_col19, #T_f7d14_row32_col20, #T_f7d14_row32_col21, #T_f7d14_row32_col22, #T_f7d14_row32_col23, #T_f7d14_row32_col24, #T_f7d14_row32_col25, #T_f7d14_row32_col26, #T_f7d14_row32_col27, #T_f7d14_row32_col28, #T_f7d14_row32_col31, #T_f7d14_row32_col32, #T_f7d14_row32_col33, #T_f7d14_row33_col2, #T_f7d14_row33_col5, #T_f7d14_row33_col6, #T_f7d14_row33_col7, #T_f7d14_row33_col8, #T_f7d14_row33_col9, #T_f7d14_row33_col10, #T_f7d14_row33_col11, #T_f7d14_row33_col12, #T_f7d14_row33_col13, #T_f7d14_row33_col14, #T_f7d14_row33_col15, #T_f7d14_row33_col16, #T_f7d14_row33_col17, #T_f7d14_row33_col18, #T_f7d14_row33_col19, #T_f7d14_row33_col20, #T_f7d14_row33_col21, #T_f7d14_row33_col22, #T_f7d14_row33_col23, #T_f7d14_row33_col24, #T_f7d14_row33_col25, #T_f7d14_row33_col26, #T_f7d14_row33_col27, #T_f7d14_row33_col28, #T_f7d14_row33_col31, #T_f7d14_row33_col32, #T_f7d14_row33_col33 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f7d14_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >revenue_diff</th>\n",
       "      <th class=\"col_heading level0 col1\" >noi_diff</th>\n",
       "      <th class=\"col_heading level0 col2\" >salescost_diff</th>\n",
       "      <th class=\"col_heading level0 col3\" >sga_diff</th>\n",
       "      <th class=\"col_heading level0 col4\" >noe_diff</th>\n",
       "      <th class=\"col_heading level0 col5\" >ctax_diff</th>\n",
       "      <th class=\"col_heading level0 col6\" >liquidLiabilities_diff</th>\n",
       "      <th class=\"col_heading level0 col7\" >NCLiabilities_diff</th>\n",
       "      <th class=\"col_heading level0 col8\" >liquidAsset_diff</th>\n",
       "      <th class=\"col_heading level0 col9\" >nonCAsset_diff</th>\n",
       "      <th class=\"col_heading level0 col10\" >sido_0.0</th>\n",
       "      <th class=\"col_heading level0 col11\" >sido_1.0</th>\n",
       "      <th class=\"col_heading level0 col12\" >sido_10.0</th>\n",
       "      <th class=\"col_heading level0 col13\" >sido_11.0</th>\n",
       "      <th class=\"col_heading level0 col14\" >sido_12.0</th>\n",
       "      <th class=\"col_heading level0 col15\" >sido_13.0</th>\n",
       "      <th class=\"col_heading level0 col16\" >sido_14.0</th>\n",
       "      <th class=\"col_heading level0 col17\" >sido_15.0</th>\n",
       "      <th class=\"col_heading level0 col18\" >sido_2.0</th>\n",
       "      <th class=\"col_heading level0 col19\" >sido_3.0</th>\n",
       "      <th class=\"col_heading level0 col20\" >sido_4.0</th>\n",
       "      <th class=\"col_heading level0 col21\" >sido_5.0</th>\n",
       "      <th class=\"col_heading level0 col22\" >sido_6.0</th>\n",
       "      <th class=\"col_heading level0 col23\" >sido_7.0</th>\n",
       "      <th class=\"col_heading level0 col24\" >sido_8.0</th>\n",
       "      <th class=\"col_heading level0 col25\" >sido_9.0</th>\n",
       "      <th class=\"col_heading level0 col26\" >instkind_0.0</th>\n",
       "      <th class=\"col_heading level0 col27\" >instkind_1.0</th>\n",
       "      <th class=\"col_heading level0 col28\" >instkind_2.0</th>\n",
       "      <th class=\"col_heading level0 col29\" >instkind_3.0</th>\n",
       "      <th class=\"col_heading level0 col30\" >instkind_4.0</th>\n",
       "      <th class=\"col_heading level0 col31\" >instkind_5.0</th>\n",
       "      <th class=\"col_heading level0 col32\" >instkind_6.0</th>\n",
       "      <th class=\"col_heading level0 col33\" >OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row0\" class=\"row_heading level0 row0\" >revenue_diff</th>\n",
       "      <td id=\"T_f7d14_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row0_col1\" class=\"data row0 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col3\" class=\"data row0 col3\" >0.922011</td>\n",
       "      <td id=\"T_f7d14_row0_col4\" class=\"data row0 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col9\" class=\"data row0 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col10\" class=\"data row0 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col16\" class=\"data row0 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col18\" class=\"data row0 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col19\" class=\"data row0 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col20\" class=\"data row0 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col21\" class=\"data row0 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col22\" class=\"data row0 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col23\" class=\"data row0 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col24\" class=\"data row0 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col25\" class=\"data row0 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col26\" class=\"data row0 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col27\" class=\"data row0 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col28\" class=\"data row0 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col29\" class=\"data row0 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col30\" class=\"data row0 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col31\" class=\"data row0 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col32\" class=\"data row0 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row0_col33\" class=\"data row0 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row1\" class=\"row_heading level0 row1\" >noi_diff</th>\n",
       "      <td id=\"T_f7d14_row1_col0\" class=\"data row1 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col4\" class=\"data row1 col4\" >0.518635</td>\n",
       "      <td id=\"T_f7d14_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col16\" class=\"data row1 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col18\" class=\"data row1 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col19\" class=\"data row1 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col20\" class=\"data row1 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col21\" class=\"data row1 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col22\" class=\"data row1 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col23\" class=\"data row1 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col24\" class=\"data row1 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col25\" class=\"data row1 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col26\" class=\"data row1 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col27\" class=\"data row1 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col28\" class=\"data row1 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col29\" class=\"data row1 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col30\" class=\"data row1 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col31\" class=\"data row1 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col32\" class=\"data row1 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row1_col33\" class=\"data row1 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row2\" class=\"row_heading level0 row2\" >salescost_diff</th>\n",
       "      <td id=\"T_f7d14_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col4\" class=\"data row2 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col5\" class=\"data row2 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col6\" class=\"data row2 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col8\" class=\"data row2 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col9\" class=\"data row2 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col10\" class=\"data row2 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col16\" class=\"data row2 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col18\" class=\"data row2 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col19\" class=\"data row2 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col20\" class=\"data row2 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col21\" class=\"data row2 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col22\" class=\"data row2 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col23\" class=\"data row2 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col24\" class=\"data row2 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col25\" class=\"data row2 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col26\" class=\"data row2 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col27\" class=\"data row2 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col28\" class=\"data row2 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col29\" class=\"data row2 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col30\" class=\"data row2 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col31\" class=\"data row2 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col32\" class=\"data row2 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row2_col33\" class=\"data row2 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row3\" class=\"row_heading level0 row3\" >sga_diff</th>\n",
       "      <td id=\"T_f7d14_row3_col0\" class=\"data row3 col0\" >0.922011</td>\n",
       "      <td id=\"T_f7d14_row3_col1\" class=\"data row3 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col2\" class=\"data row3 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row3_col4\" class=\"data row3 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col5\" class=\"data row3 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col6\" class=\"data row3 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col7\" class=\"data row3 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col8\" class=\"data row3 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col9\" class=\"data row3 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col10\" class=\"data row3 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col16\" class=\"data row3 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col18\" class=\"data row3 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col19\" class=\"data row3 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col20\" class=\"data row3 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col21\" class=\"data row3 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col22\" class=\"data row3 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col23\" class=\"data row3 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col24\" class=\"data row3 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col25\" class=\"data row3 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col26\" class=\"data row3 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col27\" class=\"data row3 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col28\" class=\"data row3 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col29\" class=\"data row3 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col30\" class=\"data row3 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col31\" class=\"data row3 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col32\" class=\"data row3 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row3_col33\" class=\"data row3 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row4\" class=\"row_heading level0 row4\" >noe_diff</th>\n",
       "      <td id=\"T_f7d14_row4_col0\" class=\"data row4 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col1\" class=\"data row4 col1\" >0.518635</td>\n",
       "      <td id=\"T_f7d14_row4_col2\" class=\"data row4 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col3\" class=\"data row4 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row4_col5\" class=\"data row4 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col6\" class=\"data row4 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col7\" class=\"data row4 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col8\" class=\"data row4 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col9\" class=\"data row4 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col10\" class=\"data row4 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col16\" class=\"data row4 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col18\" class=\"data row4 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col19\" class=\"data row4 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col20\" class=\"data row4 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col21\" class=\"data row4 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col22\" class=\"data row4 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col23\" class=\"data row4 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col24\" class=\"data row4 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col25\" class=\"data row4 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col26\" class=\"data row4 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col27\" class=\"data row4 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col28\" class=\"data row4 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col29\" class=\"data row4 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col30\" class=\"data row4 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col31\" class=\"data row4 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col32\" class=\"data row4 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row4_col33\" class=\"data row4 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row5\" class=\"row_heading level0 row5\" >ctax_diff</th>\n",
       "      <td id=\"T_f7d14_row5_col0\" class=\"data row5 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col1\" class=\"data row5 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col2\" class=\"data row5 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col3\" class=\"data row5 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col4\" class=\"data row5 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row5_col6\" class=\"data row5 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col7\" class=\"data row5 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col8\" class=\"data row5 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col9\" class=\"data row5 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col10\" class=\"data row5 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col11\" class=\"data row5 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col12\" class=\"data row5 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col13\" class=\"data row5 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col14\" class=\"data row5 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col15\" class=\"data row5 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col16\" class=\"data row5 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col17\" class=\"data row5 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col18\" class=\"data row5 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col19\" class=\"data row5 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col20\" class=\"data row5 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col21\" class=\"data row5 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col22\" class=\"data row5 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col23\" class=\"data row5 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col24\" class=\"data row5 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col25\" class=\"data row5 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col26\" class=\"data row5 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col27\" class=\"data row5 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col28\" class=\"data row5 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col29\" class=\"data row5 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col30\" class=\"data row5 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col31\" class=\"data row5 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col32\" class=\"data row5 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row5_col33\" class=\"data row5 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row6\" class=\"row_heading level0 row6\" >liquidLiabilities_diff</th>\n",
       "      <td id=\"T_f7d14_row6_col0\" class=\"data row6 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col1\" class=\"data row6 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col2\" class=\"data row6 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col3\" class=\"data row6 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col4\" class=\"data row6 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col5\" class=\"data row6 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row6_col7\" class=\"data row6 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col8\" class=\"data row6 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col9\" class=\"data row6 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col10\" class=\"data row6 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col11\" class=\"data row6 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col12\" class=\"data row6 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col13\" class=\"data row6 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col14\" class=\"data row6 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col15\" class=\"data row6 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col16\" class=\"data row6 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col17\" class=\"data row6 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col18\" class=\"data row6 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col19\" class=\"data row6 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col20\" class=\"data row6 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col21\" class=\"data row6 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col22\" class=\"data row6 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col23\" class=\"data row6 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col24\" class=\"data row6 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col25\" class=\"data row6 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col26\" class=\"data row6 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col27\" class=\"data row6 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col28\" class=\"data row6 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col29\" class=\"data row6 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col30\" class=\"data row6 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col31\" class=\"data row6 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col32\" class=\"data row6 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row6_col33\" class=\"data row6 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row7\" class=\"row_heading level0 row7\" >NCLiabilities_diff</th>\n",
       "      <td id=\"T_f7d14_row7_col0\" class=\"data row7 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col1\" class=\"data row7 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col2\" class=\"data row7 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col3\" class=\"data row7 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col4\" class=\"data row7 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col5\" class=\"data row7 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col6\" class=\"data row7 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row7_col8\" class=\"data row7 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col9\" class=\"data row7 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col10\" class=\"data row7 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col11\" class=\"data row7 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col12\" class=\"data row7 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col13\" class=\"data row7 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col14\" class=\"data row7 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col15\" class=\"data row7 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col16\" class=\"data row7 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col17\" class=\"data row7 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col18\" class=\"data row7 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col19\" class=\"data row7 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col20\" class=\"data row7 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col21\" class=\"data row7 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col22\" class=\"data row7 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col23\" class=\"data row7 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col24\" class=\"data row7 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col25\" class=\"data row7 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col26\" class=\"data row7 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col27\" class=\"data row7 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col28\" class=\"data row7 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col29\" class=\"data row7 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col30\" class=\"data row7 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col31\" class=\"data row7 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col32\" class=\"data row7 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row7_col33\" class=\"data row7 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row8\" class=\"row_heading level0 row8\" >liquidAsset_diff</th>\n",
       "      <td id=\"T_f7d14_row8_col0\" class=\"data row8 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col1\" class=\"data row8 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col2\" class=\"data row8 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col3\" class=\"data row8 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col4\" class=\"data row8 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col5\" class=\"data row8 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col6\" class=\"data row8 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col7\" class=\"data row8 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col8\" class=\"data row8 col8\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row8_col9\" class=\"data row8 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col10\" class=\"data row8 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col11\" class=\"data row8 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col12\" class=\"data row8 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col13\" class=\"data row8 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col14\" class=\"data row8 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col15\" class=\"data row8 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col16\" class=\"data row8 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col17\" class=\"data row8 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col18\" class=\"data row8 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col19\" class=\"data row8 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col20\" class=\"data row8 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col21\" class=\"data row8 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col22\" class=\"data row8 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col23\" class=\"data row8 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col24\" class=\"data row8 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col25\" class=\"data row8 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col26\" class=\"data row8 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col27\" class=\"data row8 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col28\" class=\"data row8 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col29\" class=\"data row8 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col30\" class=\"data row8 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col31\" class=\"data row8 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col32\" class=\"data row8 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row8_col33\" class=\"data row8 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row9\" class=\"row_heading level0 row9\" >nonCAsset_diff</th>\n",
       "      <td id=\"T_f7d14_row9_col0\" class=\"data row9 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col1\" class=\"data row9 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col2\" class=\"data row9 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col3\" class=\"data row9 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col4\" class=\"data row9 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col5\" class=\"data row9 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col6\" class=\"data row9 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col7\" class=\"data row9 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col8\" class=\"data row9 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col9\" class=\"data row9 col9\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row9_col10\" class=\"data row9 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col11\" class=\"data row9 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col12\" class=\"data row9 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col13\" class=\"data row9 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col14\" class=\"data row9 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col15\" class=\"data row9 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col16\" class=\"data row9 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col17\" class=\"data row9 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col18\" class=\"data row9 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col19\" class=\"data row9 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col20\" class=\"data row9 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col21\" class=\"data row9 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col22\" class=\"data row9 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col23\" class=\"data row9 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col24\" class=\"data row9 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col25\" class=\"data row9 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col26\" class=\"data row9 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col27\" class=\"data row9 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col28\" class=\"data row9 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col29\" class=\"data row9 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col30\" class=\"data row9 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col31\" class=\"data row9 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col32\" class=\"data row9 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row9_col33\" class=\"data row9 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row10\" class=\"row_heading level0 row10\" >sido_0.0</th>\n",
       "      <td id=\"T_f7d14_row10_col0\" class=\"data row10 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col1\" class=\"data row10 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col2\" class=\"data row10 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col3\" class=\"data row10 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col4\" class=\"data row10 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col5\" class=\"data row10 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col6\" class=\"data row10 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col7\" class=\"data row10 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col8\" class=\"data row10 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col9\" class=\"data row10 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col10\" class=\"data row10 col10\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row10_col11\" class=\"data row10 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col12\" class=\"data row10 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col13\" class=\"data row10 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col14\" class=\"data row10 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col15\" class=\"data row10 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col16\" class=\"data row10 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col17\" class=\"data row10 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col18\" class=\"data row10 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col19\" class=\"data row10 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col20\" class=\"data row10 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col21\" class=\"data row10 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col22\" class=\"data row10 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col23\" class=\"data row10 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col24\" class=\"data row10 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col25\" class=\"data row10 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col26\" class=\"data row10 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col27\" class=\"data row10 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col28\" class=\"data row10 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col29\" class=\"data row10 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col30\" class=\"data row10 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col31\" class=\"data row10 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col32\" class=\"data row10 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row10_col33\" class=\"data row10 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row11\" class=\"row_heading level0 row11\" >sido_1.0</th>\n",
       "      <td id=\"T_f7d14_row11_col0\" class=\"data row11 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col1\" class=\"data row11 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col2\" class=\"data row11 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col3\" class=\"data row11 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col4\" class=\"data row11 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col5\" class=\"data row11 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col6\" class=\"data row11 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col7\" class=\"data row11 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col8\" class=\"data row11 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col9\" class=\"data row11 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col10\" class=\"data row11 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col11\" class=\"data row11 col11\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row11_col12\" class=\"data row11 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col13\" class=\"data row11 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col14\" class=\"data row11 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col15\" class=\"data row11 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col16\" class=\"data row11 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col17\" class=\"data row11 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col18\" class=\"data row11 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col19\" class=\"data row11 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col20\" class=\"data row11 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col21\" class=\"data row11 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col22\" class=\"data row11 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col23\" class=\"data row11 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col24\" class=\"data row11 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col25\" class=\"data row11 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col26\" class=\"data row11 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col27\" class=\"data row11 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col28\" class=\"data row11 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col29\" class=\"data row11 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col30\" class=\"data row11 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col31\" class=\"data row11 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col32\" class=\"data row11 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row11_col33\" class=\"data row11 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row12\" class=\"row_heading level0 row12\" >sido_10.0</th>\n",
       "      <td id=\"T_f7d14_row12_col0\" class=\"data row12 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col1\" class=\"data row12 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col2\" class=\"data row12 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col3\" class=\"data row12 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col4\" class=\"data row12 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col5\" class=\"data row12 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col6\" class=\"data row12 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col7\" class=\"data row12 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col8\" class=\"data row12 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col9\" class=\"data row12 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col10\" class=\"data row12 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col11\" class=\"data row12 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col12\" class=\"data row12 col12\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row12_col13\" class=\"data row12 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col14\" class=\"data row12 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col15\" class=\"data row12 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col16\" class=\"data row12 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col17\" class=\"data row12 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col18\" class=\"data row12 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col19\" class=\"data row12 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col20\" class=\"data row12 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col21\" class=\"data row12 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col22\" class=\"data row12 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col23\" class=\"data row12 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col24\" class=\"data row12 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col25\" class=\"data row12 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col26\" class=\"data row12 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col27\" class=\"data row12 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col28\" class=\"data row12 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col29\" class=\"data row12 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col30\" class=\"data row12 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col31\" class=\"data row12 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col32\" class=\"data row12 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row12_col33\" class=\"data row12 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row13\" class=\"row_heading level0 row13\" >sido_11.0</th>\n",
       "      <td id=\"T_f7d14_row13_col0\" class=\"data row13 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col1\" class=\"data row13 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col2\" class=\"data row13 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col3\" class=\"data row13 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col4\" class=\"data row13 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col5\" class=\"data row13 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col6\" class=\"data row13 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col7\" class=\"data row13 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col8\" class=\"data row13 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col9\" class=\"data row13 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col10\" class=\"data row13 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col11\" class=\"data row13 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col12\" class=\"data row13 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col13\" class=\"data row13 col13\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row13_col14\" class=\"data row13 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col15\" class=\"data row13 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col16\" class=\"data row13 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col17\" class=\"data row13 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col18\" class=\"data row13 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col19\" class=\"data row13 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col20\" class=\"data row13 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col21\" class=\"data row13 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col22\" class=\"data row13 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col23\" class=\"data row13 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col24\" class=\"data row13 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col25\" class=\"data row13 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col26\" class=\"data row13 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col27\" class=\"data row13 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col28\" class=\"data row13 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col29\" class=\"data row13 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col30\" class=\"data row13 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col31\" class=\"data row13 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col32\" class=\"data row13 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row13_col33\" class=\"data row13 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row14\" class=\"row_heading level0 row14\" >sido_12.0</th>\n",
       "      <td id=\"T_f7d14_row14_col0\" class=\"data row14 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col1\" class=\"data row14 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col2\" class=\"data row14 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col3\" class=\"data row14 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col4\" class=\"data row14 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col5\" class=\"data row14 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col6\" class=\"data row14 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col7\" class=\"data row14 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col8\" class=\"data row14 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col9\" class=\"data row14 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col10\" class=\"data row14 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col11\" class=\"data row14 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col12\" class=\"data row14 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col13\" class=\"data row14 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col14\" class=\"data row14 col14\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row14_col15\" class=\"data row14 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col16\" class=\"data row14 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col17\" class=\"data row14 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col18\" class=\"data row14 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col19\" class=\"data row14 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col20\" class=\"data row14 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col21\" class=\"data row14 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col22\" class=\"data row14 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col23\" class=\"data row14 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col24\" class=\"data row14 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col25\" class=\"data row14 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col26\" class=\"data row14 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col27\" class=\"data row14 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col28\" class=\"data row14 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col29\" class=\"data row14 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col30\" class=\"data row14 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col31\" class=\"data row14 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col32\" class=\"data row14 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row14_col33\" class=\"data row14 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row15\" class=\"row_heading level0 row15\" >sido_13.0</th>\n",
       "      <td id=\"T_f7d14_row15_col0\" class=\"data row15 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col1\" class=\"data row15 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col2\" class=\"data row15 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col3\" class=\"data row15 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col4\" class=\"data row15 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col5\" class=\"data row15 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col6\" class=\"data row15 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col7\" class=\"data row15 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col8\" class=\"data row15 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col9\" class=\"data row15 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col10\" class=\"data row15 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col11\" class=\"data row15 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col12\" class=\"data row15 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col13\" class=\"data row15 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col14\" class=\"data row15 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col15\" class=\"data row15 col15\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row15_col16\" class=\"data row15 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col17\" class=\"data row15 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col18\" class=\"data row15 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col19\" class=\"data row15 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col20\" class=\"data row15 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col21\" class=\"data row15 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col22\" class=\"data row15 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col23\" class=\"data row15 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col24\" class=\"data row15 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col25\" class=\"data row15 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col26\" class=\"data row15 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col27\" class=\"data row15 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col28\" class=\"data row15 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col29\" class=\"data row15 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col30\" class=\"data row15 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col31\" class=\"data row15 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col32\" class=\"data row15 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row15_col33\" class=\"data row15 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row16\" class=\"row_heading level0 row16\" >sido_14.0</th>\n",
       "      <td id=\"T_f7d14_row16_col0\" class=\"data row16 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col1\" class=\"data row16 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col2\" class=\"data row16 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col3\" class=\"data row16 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col4\" class=\"data row16 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col5\" class=\"data row16 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col6\" class=\"data row16 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col7\" class=\"data row16 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col8\" class=\"data row16 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col9\" class=\"data row16 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col10\" class=\"data row16 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col11\" class=\"data row16 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col12\" class=\"data row16 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col13\" class=\"data row16 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col14\" class=\"data row16 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col15\" class=\"data row16 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col16\" class=\"data row16 col16\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row16_col17\" class=\"data row16 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col18\" class=\"data row16 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col19\" class=\"data row16 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col20\" class=\"data row16 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col21\" class=\"data row16 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col22\" class=\"data row16 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col23\" class=\"data row16 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col24\" class=\"data row16 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col25\" class=\"data row16 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col26\" class=\"data row16 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col27\" class=\"data row16 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col28\" class=\"data row16 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col29\" class=\"data row16 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col30\" class=\"data row16 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col31\" class=\"data row16 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col32\" class=\"data row16 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row16_col33\" class=\"data row16 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row17\" class=\"row_heading level0 row17\" >sido_15.0</th>\n",
       "      <td id=\"T_f7d14_row17_col0\" class=\"data row17 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col1\" class=\"data row17 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col2\" class=\"data row17 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col3\" class=\"data row17 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col4\" class=\"data row17 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col5\" class=\"data row17 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col6\" class=\"data row17 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col7\" class=\"data row17 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col8\" class=\"data row17 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col9\" class=\"data row17 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col10\" class=\"data row17 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col11\" class=\"data row17 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col12\" class=\"data row17 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col13\" class=\"data row17 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col14\" class=\"data row17 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col15\" class=\"data row17 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col16\" class=\"data row17 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col17\" class=\"data row17 col17\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row17_col18\" class=\"data row17 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col19\" class=\"data row17 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col20\" class=\"data row17 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col21\" class=\"data row17 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col22\" class=\"data row17 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col23\" class=\"data row17 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col24\" class=\"data row17 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col25\" class=\"data row17 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col26\" class=\"data row17 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col27\" class=\"data row17 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col28\" class=\"data row17 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col29\" class=\"data row17 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col30\" class=\"data row17 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col31\" class=\"data row17 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col32\" class=\"data row17 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row17_col33\" class=\"data row17 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row18\" class=\"row_heading level0 row18\" >sido_2.0</th>\n",
       "      <td id=\"T_f7d14_row18_col0\" class=\"data row18 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col1\" class=\"data row18 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col2\" class=\"data row18 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col3\" class=\"data row18 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col4\" class=\"data row18 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col5\" class=\"data row18 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col6\" class=\"data row18 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col7\" class=\"data row18 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col8\" class=\"data row18 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col9\" class=\"data row18 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col10\" class=\"data row18 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col11\" class=\"data row18 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col12\" class=\"data row18 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col13\" class=\"data row18 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col14\" class=\"data row18 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col15\" class=\"data row18 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col16\" class=\"data row18 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col17\" class=\"data row18 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col18\" class=\"data row18 col18\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row18_col19\" class=\"data row18 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col20\" class=\"data row18 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col21\" class=\"data row18 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col22\" class=\"data row18 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col23\" class=\"data row18 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col24\" class=\"data row18 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col25\" class=\"data row18 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col26\" class=\"data row18 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col27\" class=\"data row18 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col28\" class=\"data row18 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col29\" class=\"data row18 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col30\" class=\"data row18 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col31\" class=\"data row18 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col32\" class=\"data row18 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row18_col33\" class=\"data row18 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row19\" class=\"row_heading level0 row19\" >sido_3.0</th>\n",
       "      <td id=\"T_f7d14_row19_col0\" class=\"data row19 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col1\" class=\"data row19 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col2\" class=\"data row19 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col3\" class=\"data row19 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col4\" class=\"data row19 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col5\" class=\"data row19 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col6\" class=\"data row19 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col7\" class=\"data row19 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col8\" class=\"data row19 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col9\" class=\"data row19 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col10\" class=\"data row19 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col11\" class=\"data row19 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col12\" class=\"data row19 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col13\" class=\"data row19 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col14\" class=\"data row19 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col15\" class=\"data row19 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col16\" class=\"data row19 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col17\" class=\"data row19 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col18\" class=\"data row19 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col19\" class=\"data row19 col19\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row19_col20\" class=\"data row19 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col21\" class=\"data row19 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col22\" class=\"data row19 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col23\" class=\"data row19 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col24\" class=\"data row19 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col25\" class=\"data row19 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col26\" class=\"data row19 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col27\" class=\"data row19 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col28\" class=\"data row19 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col29\" class=\"data row19 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col30\" class=\"data row19 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col31\" class=\"data row19 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col32\" class=\"data row19 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row19_col33\" class=\"data row19 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row20\" class=\"row_heading level0 row20\" >sido_4.0</th>\n",
       "      <td id=\"T_f7d14_row20_col0\" class=\"data row20 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col1\" class=\"data row20 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col2\" class=\"data row20 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col3\" class=\"data row20 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col4\" class=\"data row20 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col5\" class=\"data row20 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col6\" class=\"data row20 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col7\" class=\"data row20 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col8\" class=\"data row20 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col9\" class=\"data row20 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col10\" class=\"data row20 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col11\" class=\"data row20 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col12\" class=\"data row20 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col13\" class=\"data row20 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col14\" class=\"data row20 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col15\" class=\"data row20 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col16\" class=\"data row20 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col17\" class=\"data row20 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col18\" class=\"data row20 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col19\" class=\"data row20 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col20\" class=\"data row20 col20\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row20_col21\" class=\"data row20 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col22\" class=\"data row20 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col23\" class=\"data row20 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col24\" class=\"data row20 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col25\" class=\"data row20 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col26\" class=\"data row20 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col27\" class=\"data row20 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col28\" class=\"data row20 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col29\" class=\"data row20 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col30\" class=\"data row20 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col31\" class=\"data row20 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col32\" class=\"data row20 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row20_col33\" class=\"data row20 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row21\" class=\"row_heading level0 row21\" >sido_5.0</th>\n",
       "      <td id=\"T_f7d14_row21_col0\" class=\"data row21 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col1\" class=\"data row21 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col2\" class=\"data row21 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col3\" class=\"data row21 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col4\" class=\"data row21 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col5\" class=\"data row21 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col6\" class=\"data row21 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col7\" class=\"data row21 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col8\" class=\"data row21 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col9\" class=\"data row21 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col10\" class=\"data row21 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col11\" class=\"data row21 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col12\" class=\"data row21 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col13\" class=\"data row21 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col14\" class=\"data row21 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col15\" class=\"data row21 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col16\" class=\"data row21 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col17\" class=\"data row21 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col18\" class=\"data row21 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col19\" class=\"data row21 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col20\" class=\"data row21 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col21\" class=\"data row21 col21\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row21_col22\" class=\"data row21 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col23\" class=\"data row21 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col24\" class=\"data row21 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col25\" class=\"data row21 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col26\" class=\"data row21 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col27\" class=\"data row21 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col28\" class=\"data row21 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col29\" class=\"data row21 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col30\" class=\"data row21 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col31\" class=\"data row21 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col32\" class=\"data row21 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row21_col33\" class=\"data row21 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row22\" class=\"row_heading level0 row22\" >sido_6.0</th>\n",
       "      <td id=\"T_f7d14_row22_col0\" class=\"data row22 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col1\" class=\"data row22 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col2\" class=\"data row22 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col3\" class=\"data row22 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col4\" class=\"data row22 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col5\" class=\"data row22 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col6\" class=\"data row22 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col7\" class=\"data row22 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col8\" class=\"data row22 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col9\" class=\"data row22 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col10\" class=\"data row22 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col11\" class=\"data row22 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col12\" class=\"data row22 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col13\" class=\"data row22 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col14\" class=\"data row22 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col15\" class=\"data row22 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col16\" class=\"data row22 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col17\" class=\"data row22 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col18\" class=\"data row22 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col19\" class=\"data row22 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col20\" class=\"data row22 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col21\" class=\"data row22 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col22\" class=\"data row22 col22\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row22_col23\" class=\"data row22 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col24\" class=\"data row22 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col25\" class=\"data row22 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col26\" class=\"data row22 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col27\" class=\"data row22 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col28\" class=\"data row22 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col29\" class=\"data row22 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col30\" class=\"data row22 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col31\" class=\"data row22 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col32\" class=\"data row22 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row22_col33\" class=\"data row22 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row23\" class=\"row_heading level0 row23\" >sido_7.0</th>\n",
       "      <td id=\"T_f7d14_row23_col0\" class=\"data row23 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col1\" class=\"data row23 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col2\" class=\"data row23 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col3\" class=\"data row23 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col4\" class=\"data row23 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col5\" class=\"data row23 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col6\" class=\"data row23 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col7\" class=\"data row23 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col8\" class=\"data row23 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col9\" class=\"data row23 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col10\" class=\"data row23 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col11\" class=\"data row23 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col12\" class=\"data row23 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col13\" class=\"data row23 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col14\" class=\"data row23 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col15\" class=\"data row23 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col16\" class=\"data row23 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col17\" class=\"data row23 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col18\" class=\"data row23 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col19\" class=\"data row23 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col20\" class=\"data row23 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col21\" class=\"data row23 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col22\" class=\"data row23 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col23\" class=\"data row23 col23\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row23_col24\" class=\"data row23 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col25\" class=\"data row23 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col26\" class=\"data row23 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col27\" class=\"data row23 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col28\" class=\"data row23 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col29\" class=\"data row23 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col30\" class=\"data row23 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col31\" class=\"data row23 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col32\" class=\"data row23 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row23_col33\" class=\"data row23 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row24\" class=\"row_heading level0 row24\" >sido_8.0</th>\n",
       "      <td id=\"T_f7d14_row24_col0\" class=\"data row24 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col1\" class=\"data row24 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col2\" class=\"data row24 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col3\" class=\"data row24 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col4\" class=\"data row24 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col5\" class=\"data row24 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col6\" class=\"data row24 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col7\" class=\"data row24 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col8\" class=\"data row24 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col9\" class=\"data row24 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col10\" class=\"data row24 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col11\" class=\"data row24 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col12\" class=\"data row24 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col13\" class=\"data row24 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col14\" class=\"data row24 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col15\" class=\"data row24 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col16\" class=\"data row24 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col17\" class=\"data row24 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col18\" class=\"data row24 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col19\" class=\"data row24 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col20\" class=\"data row24 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col21\" class=\"data row24 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col22\" class=\"data row24 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col23\" class=\"data row24 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col24\" class=\"data row24 col24\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row24_col25\" class=\"data row24 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col26\" class=\"data row24 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col27\" class=\"data row24 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col28\" class=\"data row24 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col29\" class=\"data row24 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col30\" class=\"data row24 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col31\" class=\"data row24 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col32\" class=\"data row24 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row24_col33\" class=\"data row24 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row25\" class=\"row_heading level0 row25\" >sido_9.0</th>\n",
       "      <td id=\"T_f7d14_row25_col0\" class=\"data row25 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col1\" class=\"data row25 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col2\" class=\"data row25 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col3\" class=\"data row25 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col4\" class=\"data row25 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col5\" class=\"data row25 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col6\" class=\"data row25 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col7\" class=\"data row25 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col8\" class=\"data row25 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col9\" class=\"data row25 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col10\" class=\"data row25 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col11\" class=\"data row25 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col12\" class=\"data row25 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col13\" class=\"data row25 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col14\" class=\"data row25 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col15\" class=\"data row25 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col16\" class=\"data row25 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col17\" class=\"data row25 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col18\" class=\"data row25 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col19\" class=\"data row25 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col20\" class=\"data row25 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col21\" class=\"data row25 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col22\" class=\"data row25 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col23\" class=\"data row25 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col24\" class=\"data row25 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col25\" class=\"data row25 col25\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row25_col26\" class=\"data row25 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col27\" class=\"data row25 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col28\" class=\"data row25 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col29\" class=\"data row25 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col30\" class=\"data row25 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col31\" class=\"data row25 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col32\" class=\"data row25 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row25_col33\" class=\"data row25 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row26\" class=\"row_heading level0 row26\" >instkind_0.0</th>\n",
       "      <td id=\"T_f7d14_row26_col0\" class=\"data row26 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col1\" class=\"data row26 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col2\" class=\"data row26 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col3\" class=\"data row26 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col4\" class=\"data row26 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col5\" class=\"data row26 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col6\" class=\"data row26 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col7\" class=\"data row26 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col8\" class=\"data row26 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col9\" class=\"data row26 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col10\" class=\"data row26 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col11\" class=\"data row26 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col12\" class=\"data row26 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col13\" class=\"data row26 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col14\" class=\"data row26 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col15\" class=\"data row26 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col16\" class=\"data row26 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col17\" class=\"data row26 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col18\" class=\"data row26 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col19\" class=\"data row26 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col20\" class=\"data row26 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col21\" class=\"data row26 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col22\" class=\"data row26 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col23\" class=\"data row26 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col24\" class=\"data row26 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col25\" class=\"data row26 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col26\" class=\"data row26 col26\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row26_col27\" class=\"data row26 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col28\" class=\"data row26 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col29\" class=\"data row26 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col30\" class=\"data row26 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col31\" class=\"data row26 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col32\" class=\"data row26 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row26_col33\" class=\"data row26 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row27\" class=\"row_heading level0 row27\" >instkind_1.0</th>\n",
       "      <td id=\"T_f7d14_row27_col0\" class=\"data row27 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col1\" class=\"data row27 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col2\" class=\"data row27 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col3\" class=\"data row27 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col4\" class=\"data row27 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col5\" class=\"data row27 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col6\" class=\"data row27 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col7\" class=\"data row27 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col8\" class=\"data row27 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col9\" class=\"data row27 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col10\" class=\"data row27 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col11\" class=\"data row27 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col12\" class=\"data row27 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col13\" class=\"data row27 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col14\" class=\"data row27 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col15\" class=\"data row27 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col16\" class=\"data row27 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col17\" class=\"data row27 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col18\" class=\"data row27 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col19\" class=\"data row27 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col20\" class=\"data row27 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col21\" class=\"data row27 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col22\" class=\"data row27 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col23\" class=\"data row27 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col24\" class=\"data row27 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col25\" class=\"data row27 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col26\" class=\"data row27 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col27\" class=\"data row27 col27\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row27_col28\" class=\"data row27 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col29\" class=\"data row27 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col30\" class=\"data row27 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col31\" class=\"data row27 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col32\" class=\"data row27 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row27_col33\" class=\"data row27 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row28\" class=\"row_heading level0 row28\" >instkind_2.0</th>\n",
       "      <td id=\"T_f7d14_row28_col0\" class=\"data row28 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col1\" class=\"data row28 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col2\" class=\"data row28 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col3\" class=\"data row28 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col4\" class=\"data row28 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col5\" class=\"data row28 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col6\" class=\"data row28 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col7\" class=\"data row28 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col8\" class=\"data row28 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col9\" class=\"data row28 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col10\" class=\"data row28 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col11\" class=\"data row28 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col12\" class=\"data row28 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col13\" class=\"data row28 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col14\" class=\"data row28 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col15\" class=\"data row28 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col16\" class=\"data row28 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col17\" class=\"data row28 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col18\" class=\"data row28 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col19\" class=\"data row28 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col20\" class=\"data row28 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col21\" class=\"data row28 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col22\" class=\"data row28 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col23\" class=\"data row28 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col24\" class=\"data row28 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col25\" class=\"data row28 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col26\" class=\"data row28 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col27\" class=\"data row28 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col28\" class=\"data row28 col28\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row28_col29\" class=\"data row28 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col30\" class=\"data row28 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col31\" class=\"data row28 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col32\" class=\"data row28 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row28_col33\" class=\"data row28 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row29\" class=\"row_heading level0 row29\" >instkind_3.0</th>\n",
       "      <td id=\"T_f7d14_row29_col0\" class=\"data row29 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col1\" class=\"data row29 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col2\" class=\"data row29 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col3\" class=\"data row29 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col4\" class=\"data row29 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col5\" class=\"data row29 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col6\" class=\"data row29 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col7\" class=\"data row29 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col8\" class=\"data row29 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col9\" class=\"data row29 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col10\" class=\"data row29 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col11\" class=\"data row29 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col12\" class=\"data row29 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col13\" class=\"data row29 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col14\" class=\"data row29 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col15\" class=\"data row29 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col16\" class=\"data row29 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col17\" class=\"data row29 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col18\" class=\"data row29 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col19\" class=\"data row29 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col20\" class=\"data row29 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col21\" class=\"data row29 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col22\" class=\"data row29 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col23\" class=\"data row29 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col24\" class=\"data row29 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col25\" class=\"data row29 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col26\" class=\"data row29 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col27\" class=\"data row29 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col28\" class=\"data row29 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col29\" class=\"data row29 col29\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row29_col30\" class=\"data row29 col30\" >-0.619002</td>\n",
       "      <td id=\"T_f7d14_row29_col31\" class=\"data row29 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col32\" class=\"data row29 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row29_col33\" class=\"data row29 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row30\" class=\"row_heading level0 row30\" >instkind_4.0</th>\n",
       "      <td id=\"T_f7d14_row30_col0\" class=\"data row30 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col1\" class=\"data row30 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col2\" class=\"data row30 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col3\" class=\"data row30 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col4\" class=\"data row30 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col5\" class=\"data row30 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col6\" class=\"data row30 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col7\" class=\"data row30 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col8\" class=\"data row30 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col9\" class=\"data row30 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col10\" class=\"data row30 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col11\" class=\"data row30 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col12\" class=\"data row30 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col13\" class=\"data row30 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col14\" class=\"data row30 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col15\" class=\"data row30 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col16\" class=\"data row30 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col17\" class=\"data row30 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col18\" class=\"data row30 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col19\" class=\"data row30 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col20\" class=\"data row30 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col21\" class=\"data row30 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col22\" class=\"data row30 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col23\" class=\"data row30 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col24\" class=\"data row30 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col25\" class=\"data row30 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col26\" class=\"data row30 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col27\" class=\"data row30 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col28\" class=\"data row30 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col29\" class=\"data row30 col29\" >-0.619002</td>\n",
       "      <td id=\"T_f7d14_row30_col30\" class=\"data row30 col30\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row30_col31\" class=\"data row30 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col32\" class=\"data row30 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row30_col33\" class=\"data row30 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row31\" class=\"row_heading level0 row31\" >instkind_5.0</th>\n",
       "      <td id=\"T_f7d14_row31_col0\" class=\"data row31 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col1\" class=\"data row31 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col2\" class=\"data row31 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col3\" class=\"data row31 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col4\" class=\"data row31 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col5\" class=\"data row31 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col6\" class=\"data row31 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col7\" class=\"data row31 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col8\" class=\"data row31 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col9\" class=\"data row31 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col10\" class=\"data row31 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col11\" class=\"data row31 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col12\" class=\"data row31 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col13\" class=\"data row31 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col14\" class=\"data row31 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col15\" class=\"data row31 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col16\" class=\"data row31 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col17\" class=\"data row31 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col18\" class=\"data row31 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col19\" class=\"data row31 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col20\" class=\"data row31 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col21\" class=\"data row31 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col22\" class=\"data row31 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col23\" class=\"data row31 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col24\" class=\"data row31 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col25\" class=\"data row31 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col26\" class=\"data row31 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col27\" class=\"data row31 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col28\" class=\"data row31 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col29\" class=\"data row31 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col30\" class=\"data row31 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col31\" class=\"data row31 col31\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row31_col32\" class=\"data row31 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row31_col33\" class=\"data row31 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row32\" class=\"row_heading level0 row32\" >instkind_6.0</th>\n",
       "      <td id=\"T_f7d14_row32_col0\" class=\"data row32 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col1\" class=\"data row32 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col2\" class=\"data row32 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col3\" class=\"data row32 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col4\" class=\"data row32 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col5\" class=\"data row32 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col6\" class=\"data row32 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col7\" class=\"data row32 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col8\" class=\"data row32 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col9\" class=\"data row32 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col10\" class=\"data row32 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col11\" class=\"data row32 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col12\" class=\"data row32 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col13\" class=\"data row32 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col14\" class=\"data row32 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col15\" class=\"data row32 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col16\" class=\"data row32 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col17\" class=\"data row32 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col18\" class=\"data row32 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col19\" class=\"data row32 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col20\" class=\"data row32 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col21\" class=\"data row32 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col22\" class=\"data row32 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col23\" class=\"data row32 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col24\" class=\"data row32 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col25\" class=\"data row32 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col26\" class=\"data row32 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col27\" class=\"data row32 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col28\" class=\"data row32 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col29\" class=\"data row32 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col30\" class=\"data row32 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col31\" class=\"data row32 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row32_col32\" class=\"data row32 col32\" >1.000000</td>\n",
       "      <td id=\"T_f7d14_row32_col33\" class=\"data row32 col33\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7d14_level0_row33\" class=\"row_heading level0 row33\" >OC</th>\n",
       "      <td id=\"T_f7d14_row33_col0\" class=\"data row33 col0\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col1\" class=\"data row33 col1\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col2\" class=\"data row33 col2\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col3\" class=\"data row33 col3\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col4\" class=\"data row33 col4\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col5\" class=\"data row33 col5\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col6\" class=\"data row33 col6\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col7\" class=\"data row33 col7\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col8\" class=\"data row33 col8\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col9\" class=\"data row33 col9\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col10\" class=\"data row33 col10\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col11\" class=\"data row33 col11\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col12\" class=\"data row33 col12\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col13\" class=\"data row33 col13\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col14\" class=\"data row33 col14\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col15\" class=\"data row33 col15\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col16\" class=\"data row33 col16\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col17\" class=\"data row33 col17\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col18\" class=\"data row33 col18\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col19\" class=\"data row33 col19\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col20\" class=\"data row33 col20\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col21\" class=\"data row33 col21\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col22\" class=\"data row33 col22\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col23\" class=\"data row33 col23\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col24\" class=\"data row33 col24\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col25\" class=\"data row33 col25\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col26\" class=\"data row33 col26\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col27\" class=\"data row33 col27\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col28\" class=\"data row33 col28\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col29\" class=\"data row33 col29\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col30\" class=\"data row33 col30\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col31\" class=\"data row33 col31\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col32\" class=\"data row33 col32\" >nan</td>\n",
       "      <td id=\"T_f7d14_row33_col33\" class=\"data row33 col33\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x222f2444488>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a9694649204fcba54e8a875890ad28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(ToggleButtons(_dom_classes=('layout-5e32e137061e48aabb5253870a8ffca4',), description='Selection…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VisualAnalysis(data,\n",
    "    layout=[[\"Scatter\", \"Scatter\"],\n",
    "            [\"BoxPlot\", 'Histogram']],\n",
    "               row_height=[500, 500]   # 인터페이스 전체 넓이 및 높이 지정\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preporcessing(data):\n",
    "\n",
    "    data = data_cleaning(data,*split_num_cat(data))\n",
    "\n",
    "    cols = ['revenue','noi','salescost','sga','noe','ctax','liquidLiabilities','NCLiabilities','liquidAsset','nonCAsset']\n",
    "    data = make_derivate(data,cols)\n",
    "\n",
    "    data = clip_outlier(data,min_max='min_max')\n",
    "\n",
    "    data = Scaler(data)\n",
    "    corr_map, corr_col_list = correlation_analysis(data)\n",
    "    return data, corr_map, corr_col_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     instkind  ownerChange  NCLiabilities      debt  liquidAsset  \\\n",
      "0         5.0          2.0      -0.040229 -0.179427    -0.094481   \n",
      "1         3.0          2.0      -0.042370 -0.345823     0.168683   \n",
      "2         5.0          2.0      -0.025673 -0.136004    -0.033737   \n",
      "3         3.0          2.0      -1.721866  1.027320     1.076523   \n",
      "4         3.0          2.0      -0.124572 -0.555060     0.734999   \n",
      "..        ...          ...            ...       ...          ...   \n",
      "296       5.0          2.0       0.078210 -0.342277    -0.065085   \n",
      "297       4.0          2.0      -0.025673 -0.159808    -0.217797   \n",
      "298       4.0          0.0      -0.025673 -0.190880    -0.357905   \n",
      "299       5.0          0.0      -0.025673 -0.174955    -0.870880   \n",
      "300       7.0          2.0      -0.024341 -0.141894    -0.106016   \n",
      "\n",
      "     liquidLiabilities  longLoan  netAsset  nonCAsset  quickAsset   revenue  \\\n",
      "0            -0.176396  0.015782 -0.103299  -0.251918   -0.092614 -0.372349   \n",
      "1            -0.388200  0.158383  0.673267   0.341605    0.144430  0.202216   \n",
      "2            -0.138559  0.028940 -0.085926  -0.212723   -0.043192 -0.054757   \n",
      "3             3.473874 -2.618557  0.052967   0.671743    0.903649  1.304938   \n",
      "4            -0.555487 -0.176203 -0.136602  -0.972283    0.743658 -0.067575   \n",
      "..                 ...       ...       ...        ...         ...       ...   \n",
      "296          -0.533840  0.028940 -0.018159  -0.329929   -0.061238 -0.189026   \n",
      "297          -0.169240  0.028940 -0.155223  -0.243385   -0.215930  1.617641   \n",
      "298          -0.209290  0.028940 -0.171769  -0.239567   -0.353856 -1.265802   \n",
      "299           0.198302  0.028940 -0.155223  -0.245953   -0.848973 -0.928484   \n",
      "300          -0.147811  0.028940 -0.165717  -0.279376   -0.102152 -0.395103   \n",
      "\n",
      "       salary       sga  shortLoan   surplus  tanAsset  \n",
      "0   -0.393558 -0.375021  -0.144854 -0.014944 -0.235519  \n",
      "1   -0.047524  0.094112  -0.530476  0.619788  0.395102  \n",
      "2   -0.201444 -0.210978  -0.144854 -0.071454 -0.197744  \n",
      "3    0.845384  1.390494   5.787837  0.155126  0.667238  \n",
      "4    0.213177 -0.185916   0.042388 -0.071454 -0.829771  \n",
      "..        ...       ...        ...       ...       ...  \n",
      "296 -0.553169 -0.603121  -0.144854  0.077717 -0.328727  \n",
      "297 -0.375926 -0.345959  -0.144854 -0.071454 -0.228903  \n",
      "298 -0.458599 -0.435958  -0.144854 -0.071454 -0.228903  \n",
      "299 -0.767421 -0.787951  -0.144854 -0.071454 -0.228903  \n",
      "300 -0.376774 -0.352334  -0.144854 -0.071454 -0.265478  \n",
      "\n",
      "[301 rows x 16 columns]\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "296    1\n",
      "297    0\n",
      "298    0\n",
      "299    0\n",
      "300    1\n",
      "Length: 301, dtype: int8\n",
      "svc_model score :  0.9508196721311475\n",
      "dtc_model score :  0.9016393442622951\n",
      "rtc_model score :  0.9508196721311475\n",
      "xgb_model1 score :  0.9508196721311475\n",
      "xgb_model2 score :  0.9016393442622951\n",
      "ada_model score :  0.9344262295081968\n",
      "gbc_model score :  0.9508196721311475\n",
      "rid_model score :  0.9344262295081968\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from pj2_jiyeon import load_data,train_test, EncodingTrain, prediction, main_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revenue_diff sga_diff\n",
      "noi_diff noe_diff\n",
      "sga_diff revenue_diff\n",
      "noe_diff noi_diff\n",
      "instkind_3.0 instkind_4.0\n",
      "instkind_4.0 instkind_3.0\n",
      "svc_model score :  0.9166666666666666\n",
      "dtc_model score :  0.85\n",
      "rtc_model score :  0.9166666666666666\n",
      "xgb_model1 score :  0.9166666666666666\n",
      "xgb_model2 score :  0.9166666666666666\n",
      "ada_model score :  0.9166666666666666\n",
      "gbc_model score :  0.9\n",
      "rid_model score :  0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = load_data('data/train.csv')\n",
    "data,_,_ = preporcessing(train_data)\n",
    "X, y = data.drop('OC',axis=1), data['OC']\n",
    "models = train_test(X,y)\n",
    "\n",
    "#test_data = load_data('data/test.csv')\n",
    "#data,_,_ = preporcessing(test_data)\n",
    "#prediction(models, Xtest)\n",
    "\n",
    "svc_model = models[0]\n",
    "dtc_model = models[1]\n",
    "rtc_model = models[2]\n",
    "xgb_model1 = models[3]\n",
    "ada_model = models[4]\n",
    "gbc_model = models[5]\n",
    "rid_model = models[6]\n",
    "xgb_model2 = models[7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766666666666667"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_voting_result = svc_model.predict(X)+dtc_model.predict(X)+rtc_model.predict(X)+xgb_model1.predict(X)\n",
    "hard_acc = sum(np.where(hard_voting_result > 2,1, 0) == y)/hard_voting_result.size\n",
    "hard_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9633333333333334"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_voting_result = svc_model.predict(X)+dtc_model.predict(X)+rtc_model.predict(X)+xgb_model1.predict(X)+ada_model.predict(X)+gbc_model.predict(X)+rid_model.predict(X)\n",
    "hard_acc = sum(np.where(hard_voting_result > 2,1, 0) == y)/hard_voting_result.size\n",
    "hard_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hard_voting_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습, 테스트 분리\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size = 0.2,random_state = 42,stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svc_result = svc_model.predict_proba(Xtest) #[:,]\n",
    "dtc_result = dtc_model.predict_proba(Xtest)\n",
    "rtc_result = rtc_model.predict_proba(Xtest)\n",
    "xgb_result = xgb_model1.predict_proba(Xtest)\n",
    "ada_result = ada_model.predict_proba(Xtest)\n",
    "gbc_result = gbc_model.predict_proba(Xtest)\n",
    "# rid_result = rid_model.predict_proba(Xtest)\n",
    "soft_voting_result = svc_result+ dtc_result+ rtc_result+xgb_result+ ada_result+ gbc_result #, rid_model\n",
    "soft_voting_result\n",
    "soft_acc = sum(np.array(soft_voting_result[:,0] < soft_voting_result[:,1], dtype='int') == ytest)/ytest.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc_model : 0.95\n",
      "dtc_model : 0.9333333333333333\n",
      "rtc_model : 0.95\n",
      "xgb_model1 : 0.95\n",
      "ada_model : 0.9666666666666667\n",
      "gbc_model : 0.9333333333333333\n",
      "rid_model : 0.95\n",
      "hard_voting_model :  0.9633333333333334\n",
      "soft_voting_model :  0.95\n"
     ]
    }
   ],
   "source": [
    "print(\"svc_model :\",svc_model.score(Xtest,ytest))\n",
    "print(\"dtc_model :\",dtc_model.score(Xtest,ytest))\n",
    "print(\"rtc_model :\",rtc_model.score(Xtest,ytest))\n",
    "print(\"xgb_model1 :\",xgb_model1.score(Xtest,ytest))\n",
    "print(\"ada_model :\",ada_model.score(Xtest,ytest))\n",
    "print(\"gbc_model :\",gbc_model.score(Xtest,ytest))\n",
    "print(\"rid_model :\",rid_model.score(Xtest,ytest))\n",
    "print(\"hard_voting_model : \", hard_acc)\n",
    "print(\"soft_voting_model : \", soft_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  3],\n",
       "       [ 0, 57]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytest, svc_model.predict(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  3]\n",
      " [ 0 57]]\n",
      "--------\n",
      "[[ 1  2]\n",
      " [ 2 55]]\n",
      "--------\n",
      "[[ 0  3]\n",
      " [ 0 57]]\n",
      "--------\n",
      "[[ 0  3]\n",
      " [ 0 57]]\n",
      "--------\n",
      "[[ 1  2]\n",
      " [ 0 57]]\n",
      "--------\n",
      "[[ 0  3]\n",
      " [ 1 56]]\n",
      "--------\n",
      "[[ 0  3]\n",
      " [ 0 57]]\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "models_ = [svc_model, dtc_model, rtc_model, xgb_model1, ada_model, gbc_model, rid_model]\n",
    "for i in range(7):\n",
    "    cm = confusion_matrix(ytest, models_[i].predict(Xtest))\n",
    "    print(cm)\n",
    "    print(\"--------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion_matrix 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_nm = ['svc_model', 'dtc_model', 'rtc_model', 'xgb_model1', 'ada_model', 'gbc_model', 'rid_model']\n",
    "label = ['close','open']\n",
    "\n",
    "#fig=plt.figure(figsize=(20,10))\n",
    "\n",
    "for i in range(7):\n",
    "#    subplot=fig.add_subplot(2,4,i+1)\n",
    "    plot = plot_confusion_matrix(models[i],Xtest,ytest,display_labels=label,cmap='tab20c',normalize=None)\n",
    "    plot.ax_.set_title(models_nm[i])\n",
    "#    img = Image.fromarray(np.uint8(plot.im_.get_cmap()(plot.im_.get_array())*255))\n",
    "#    subplot.imshow(img)\n",
    "#    subplot.set_title(models_nm[i])\n",
    "#    subplot.set_xticklabels(label)\n",
    "#    subplot.set_yticklabels(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>코드 검증내용(모델 검증)</h3><br>\n",
    "1. Pre-Processing for Data Cleaning<br>\n",
    "2. Feature Engineering and Variable Selection<br>\n",
    "3. Model Selection and Regularization<br>\n",
    "4. Optimization Processing<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = keras.Input(shape=(784,))\n",
    "dense = layers.Dense(64, activation=\"relu\")\n",
    "x = dense(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model():\n",
    "  \n",
    "   \n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(64, activation='elu', input_shape=(33,)),\n",
    "    layers.Dense(32, activation='elu'),\n",
    "    layers.Dropout(rate=0.2),\n",
    "    layers.Dense(16, activation='elu'),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "    \n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'data/model/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "dnn_model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revenue_diff sga_diff\n",
      "noi_diff noe_diff\n",
      "sga_diff revenue_diff\n",
      "noe_diff noi_diff\n",
      "instkind_3.0 instkind_4.0\n",
      "instkind_4.0 instkind_3.0\n",
      "svc_model score :  0.9166666666666666\n",
      "dtc_model score :  0.85\n",
      "rtc_model score :  0.9166666666666666\n",
      "xgb_model1 score :  0.9166666666666666\n",
      "xgb_model2 score :  0.9166666666666666\n",
      "ada_model score :  0.9166666666666666\n",
      "gbc_model score :  0.9\n",
      "rid_model score :  0.9166666666666666\n",
      "Epoch 1/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 2/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.2656WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 3/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 4/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1208\n",
      "Epoch 5/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1333\n",
      "Epoch 6/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 7/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1792\n",
      "Epoch 8/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 9/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 10/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 998us/step - loss: 1.1375e-07 - accuracy: 0.1333\n",
      "Epoch 11/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 12/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1375\n",
      "Epoch 13/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 14/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 15/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1375\n",
      "Epoch 16/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 17/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0617e-07 - accuracy: 0.2344WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 18/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 19/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 20/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 21/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 998us/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 22/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1792\n",
      "Epoch 23/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.2344WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 24/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1958\n",
      "Epoch 25/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 26/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 27/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0803e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 28/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1792\n",
      "Epoch 29/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1333\n",
      "Epoch 30/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 31/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1833\n",
      "Epoch 32/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1375\n",
      "Epoch 33/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 34/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0617e-07 - accuracy: 0.3125WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1875\n",
      "Epoch 35/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 36/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 37/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 38/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 39/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1875\n",
      "Epoch 40/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 41/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 42/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 998us/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 43/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 44/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 45/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 46/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.2500WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1958\n",
      "Epoch 47/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 48/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 49/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 50/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1833\n",
      "Epoch 51/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 52/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.0938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1333\n",
      "Epoch 53/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.0938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 54/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 55/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 56/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1875\n",
      "Epoch 57/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 58/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.2000\n",
      "Epoch 59/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1792\n",
      "Epoch 60/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 61/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 62/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1833\n",
      "Epoch 63/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 64/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 65/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 66/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 67/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 998us/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 68/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 69/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 70/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 71/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.0781WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 72/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 73/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 74/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 75/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 76/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1333\n",
      "Epoch 77/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 78/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 79/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 80/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 81/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 82/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1375\n",
      "Epoch 83/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 84/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 85/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 86/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 998us/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 87/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1875\n",
      "Epoch 88/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 89/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 90/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 91/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.2208\n",
      "Epoch 92/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1833\n",
      "Epoch 93/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1333\n",
      "Epoch 94/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 95/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 96/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1833\n",
      "Epoch 97/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1921e-07 - accuracy: 0.0938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 98/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.0312WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1292\n",
      "Epoch 99/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.0938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1292\n",
      "Epoch 100/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 101/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 102/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 103/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 104/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1917\n",
      "Epoch 105/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 106/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1875\n",
      "Epoch 107/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1792\n",
      "Epoch 108/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.0938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 109/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 110/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1958\n",
      "Epoch 111/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 112/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1921e-07 - accuracy: 0.0938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 113/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 114/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 115/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 116/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 117/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1921e-07 - accuracy: 0.0625WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1083\n",
      "Epoch 118/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1167\n",
      "Epoch 119/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.0781WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 120/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 121/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.0938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 998us/step - loss: 1.1375e-07 - accuracy: 0.1250\n",
      "Epoch 122/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 123/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 998us/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 124/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 125/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.0781WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1375\n",
      "Epoch 126/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 127/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1875\n",
      "Epoch 128/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.0625WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1333\n",
      "Epoch 129/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 130/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 131/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 132/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 133/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 134/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 135/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 136/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 137/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 138/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.2656WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 139/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1208\n",
      "Epoch 140/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 141/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 142/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.2344WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 143/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.2500WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.2167\n",
      "Epoch 144/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 145/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1917\n",
      "Epoch 146/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 147/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.0938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 148/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.0938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1292\n",
      "Epoch 149/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 150/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1875\n",
      "Epoch 151/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 152/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1292\n",
      "Epoch 153/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.0469WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 154/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.2344WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 155/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1292\n",
      "Epoch 156/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 157/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1125\n",
      "Epoch 158/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1375\n",
      "Epoch 159/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1375\n",
      "Epoch 160/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.0938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 161/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 162/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 163/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.2344WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 164/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 165/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 166/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1292\n",
      "Epoch 167/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1375\n",
      "Epoch 168/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 169/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1375\n",
      "Epoch 170/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1292\n",
      "Epoch 171/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.2656WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1958\n",
      "Epoch 172/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 173/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1250\n",
      "Epoch 174/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 175/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 176/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.2656WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.2000\n",
      "Epoch 177/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1375\n",
      "Epoch 178/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 179/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1375\n",
      "Epoch 180/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 998us/step - loss: 1.1375e-07 - accuracy: 0.1917\n",
      "Epoch 181/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1792\n",
      "Epoch 182/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 183/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 184/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 185/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1333\n",
      "Epoch 186/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 187/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 188/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 189/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 190/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 191/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 192/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.0781WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 193/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 194/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0803e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 195/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 196/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 197/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1792\n",
      "Epoch 198/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 199/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 200/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 201/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1833\n",
      "Epoch 202/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1292\n",
      "Epoch 203/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 204/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 205/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 206/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1792\n",
      "Epoch 207/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 208/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1833\n",
      "Epoch 209/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 210/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.0469WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1292\n",
      "Epoch 211/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.2344WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 212/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.0938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1375e-07 - accuracy: 0.1375\n",
      "Epoch 213/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 214/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1292\n",
      "Epoch 215/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.0938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1333\n",
      "Epoch 216/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1292\n",
      "Epoch 217/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 218/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 219/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 220/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1875\n",
      "Epoch 221/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 222/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 223/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 224/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.0781WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1208\n",
      "Epoch 225/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 226/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 227/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 228/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0803e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1208\n",
      "Epoch 229/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 230/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 231/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1375\n",
      "Epoch 232/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.0938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 998us/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 233/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0803e-07 - accuracy: 0.2344WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1792\n",
      "Epoch 234/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1292\n",
      "Epoch 235/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1921e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 236/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 237/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 238/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1833\n",
      "Epoch 239/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 240/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 241/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.2344WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 242/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0803e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 243/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 244/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1250\n",
      "Epoch 245/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1921e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 246/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1375\n",
      "Epoch 247/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 248/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.2000\n",
      "Epoch 249/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1875\n",
      "Epoch 250/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.0938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 251/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 252/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 253/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1921e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1375e-07 - accuracy: 0.1875\n",
      "Epoch 254/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 255/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1833\n",
      "Epoch 256/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 257/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 258/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1833\n",
      "Epoch 259/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1875\n",
      "Epoch 260/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 261/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 262/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 263/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 264/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.0781WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 265/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.2344WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1875\n",
      "Epoch 266/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 267/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1917\n",
      "Epoch 268/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 269/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1833\n",
      "Epoch 270/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 271/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 272/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1292\n",
      "Epoch 273/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 274/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 275/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 276/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1792\n",
      "Epoch 277/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.2344WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.2083\n",
      "Epoch 278/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 279/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1375e-07 - accuracy: 0.1792\n",
      "Epoch 280/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1375\n",
      "Epoch 281/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1792\n",
      "Epoch 282/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 283/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 284/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0803e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 285/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 286/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1250\n",
      "Epoch 287/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1875\n",
      "Epoch 288/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 289/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.0781WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 290/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 291/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 292/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1833\n",
      "Epoch 293/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 294/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.0938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 295/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 296/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1917\n",
      "Epoch 297/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1208\n",
      "Epoch 298/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 299/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 300/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 301/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1958\n",
      "Epoch 302/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 303/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1921e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 304/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.2000\n",
      "Epoch 305/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.0469WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1208\n",
      "Epoch 306/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 307/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 308/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 309/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0803e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 310/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 311/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 312/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 313/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.2500WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1917\n",
      "Epoch 314/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1792\n",
      "Epoch 315/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 316/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1921e-07 - accuracy: 0.0781WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 317/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 318/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 319/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.0938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1208\n",
      "Epoch 320/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0617e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1375\n",
      "Epoch 321/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 322/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 323/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 324/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 325/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 326/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.2500WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 327/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.0781WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 328/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.0938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 329/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0803e-07 - accuracy: 0.2500WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 330/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 331/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1375\n",
      "Epoch 332/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1921e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1917\n",
      "Epoch 333/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.2500WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1833\n",
      "Epoch 334/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 335/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.2344WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.2083\n",
      "Epoch 336/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 337/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 338/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 339/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 998us/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 340/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 341/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 342/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0803e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1333\n",
      "Epoch 343/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 344/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 345/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 346/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 347/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 348/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 349/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.2656WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 350/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1250\n",
      "Epoch 351/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1792\n",
      "Epoch 352/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 353/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1792\n",
      "Epoch 354/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1167\n",
      "Epoch 355/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 356/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1375\n",
      "Epoch 357/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1833\n",
      "Epoch 358/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 359/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 360/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 361/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 362/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 363/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1792\n",
      "Epoch 364/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1921e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.2000\n",
      "Epoch 365/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 366/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 367/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1917\n",
      "Epoch 368/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 369/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 370/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1375e-07 - accuracy: 0.1292\n",
      "Epoch 371/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1792\n",
      "Epoch 372/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0803e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1958\n",
      "Epoch 373/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 374/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 375/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 376/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 377/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 378/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.2500WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 379/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1375e-07 - accuracy: 0.1708\n",
      "Epoch 380/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1458\n",
      "Epoch 381/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 382/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 383/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 384/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 385/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1833\n",
      "Epoch 386/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 387/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 388/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.2031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1625\n",
      "Epoch 389/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1750\n",
      "Epoch 390/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1176e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1833\n",
      "Epoch 391/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1417\n",
      "Epoch 392/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0990e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1375\n",
      "Epoch 393/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1735e-07 - accuracy: 0.1250WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1500\n",
      "Epoch 394/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 395/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.0781WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1250\n",
      "Epoch 396/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1542\n",
      "Epoch 397/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1921e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1375e-07 - accuracy: 0.1583\n",
      "Epoch 398/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1292\n",
      "Epoch 399/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1362e-07 - accuracy: 0.1719WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1667\n",
      "Epoch 400/400\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1548e-07 - accuracy: 0.0938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1375e-07 - accuracy: 0.1375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = load_data('data/train.csv')\n",
    "data,_,_ = preporcessing(train_data)\n",
    "X, y = data.drop('OC',axis=1), data['OC']\n",
    "models = train_test(X,y)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size = 0.2,random_state = 42,stratify=y)\n",
    "\n",
    "\n",
    "history = dnn_model.fit(Xtrain,ytrain,epochs=400,batch_size=64, callbacks=[model_checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9 Kernel",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
